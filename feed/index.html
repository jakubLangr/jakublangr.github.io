<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jakub Langr's Blog</title><link>/</link><description>About data and all things awesome</description><atom:link href="http://www.jakublangr.com/feed/index.html" rel="self"></atom:link><lastBuildDate>Mon, 14 Sep 2015 21:00:00 +0100</lastBuildDate><item><title>...especially about the future</title><link>/gjp-part2.html</link><description>&lt;p&gt;A year has passed since I started to make predictions for this fascinating project run by Philip Tetlock a man that has dedicated about 30 years of his life to understanding geo-political forecasting. Recently the project has ended so I would like to share some insights.&lt;/p&gt;
&lt;p&gt;First and foremost, I would love to start with &lt;a href="hello-world.html"&gt;evaluation of my own lessons&lt;/a&gt;: I think that overall I ended up over-correcting for the biases I have read about, which is a fascinating lesson. I already mentioned this the &lt;a href="hello-world.html"&gt;first time I was writing&lt;/a&gt; about Good Judgment Project (GJP). At least based on my rudimentary understanding the calibration and observation, it seems that normally people have the opposite bias and the curve is flipped around the 45 degree line (the picture below is from the report I received from Good Judgment Project).&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/calibration_curve.png" alt="(Calibration)" align='right' height='300px' weight='300px' /&gt;&lt;/p&gt;
&lt;p&gt;My second point about randomness was just due to my un-rigorous understanding of randomness that I think I now understand: the problem is that something is random given a certain distribution (so we cannot make a better guess than the observed distribution for any particular observation). My third lesson about conditional probability still remains fair, which is: it is difficult to make it correctly, but as Philip Tetlock correctly pointed out, this is the way forward, because it allows us to get exactly the probabilities we care about: if we do X what will the world do? (Because we do not care about if Iran will build a nuclear bomb, we want to know IF we do nothing will Iran build a nuclear bomb?) 
sting as the project I have been using much during GJP--but they will "soon" be announcing what they are doing next, but who knows what that will entail. &lt;/p&gt;
&lt;p&gt;So when the results rolled in they were not too bad, I ended up being the 71st percentile, with my imputed scores dragging me down a little (this was necessary, because you could not answer all the questions, though maybe I also picked questions I understood better). &lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/mean_brier.png" height='400px' width='800px' align='center' /&gt;
&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/density_imputed_comparison.png" height='400px' width='800px' align='center' /&gt;&lt;/p&gt;
&lt;p&gt;So I think the overall results were quite decent, but I certainly I have loads to learn! While Philip Tetlock certainly tries to help us mere mortals in the &lt;a href="http://edge.org/conversation/philip_tetlock-edge-master-class-2015-a-short-course-in-superforecasting-class-iii"&gt;the political forecasting by giving us better insight in the Edge online seminar&lt;/a&gt;. I have not watched all of them, but they seem amazing so far! &lt;/p&gt;
&lt;p&gt;I think what GJP mainly showed me is the power of prediction markets: we can not only &lt;a href="https://web.archive.org/web/20150813062234/http://www.columbia.edu/~bc2656/GooglePredictionMarketPaper.pdf"&gt;use them in companies to guide our own progress&lt;/a&gt;, but we can also use them to &lt;a href="https://home.inklingmarkets.com/"&gt;get a glimpse into the future like Inkling Markets does&lt;/a&gt; by pooling our predictions together in a crowd-sourcing manner. This last link is particularly interesting, as I feel this has &lt;em&gt;many&lt;/em&gt; commercial applications if only people cared enough about evidence. &lt;/p&gt;
&lt;p&gt;Philip Tetlock outlines what are the necessary ingredients of good forecasting and he mentions that the best forecasters tend to be publicly minded software engineers, which is partially supported by the Google information flow study and generally it seems that the more quantitative the subject the better you are likely to be as one political forecasting study finds that the &lt;a href="https://web.archive.org/web/20150614075429/http://www.hamilton.edu/documents/Analysis-of-Forcast-Accuracy-in-the-Political-Media.pdf"&gt;best forecasters in US politics&lt;/a&gt; "tend to be liberal and not lawyers" (most of the good ones were economist, interestingly). &lt;/p&gt;
&lt;p&gt;But I think there is a potential array of problems: are we not likely to fall into the same illusion as with actual financial markets? E.g. that they are &lt;em&gt;always&lt;/em&gt; efficient and therefore we should almost blindly trust them (as seems to be the narrative in the Conservative US politics)? Surely, given that we now know that most people are not better at forecasting than random (though this may be because all of the stastically efficient arbitration has already been done in financial markets by the algorithmic hedge funds). I think this is up for discussion, but I would definitely not try to apply them to policy debates blindly &lt;a href="http://squid314.livejournal.com/352406.html"&gt;as some authors do&lt;/a&gt;: &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Prediction markets avoid these problems. There is no question of who the experts are: anyone can invest in a prediction market. There's no question of special interests taking it over; this just distributes free money to more honest investors.&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;My other problem is that while applications in business are fascinating, the sample sizes with exception of &lt;em&gt;huge&lt;/em&gt; (and data-driven?) companies such as Google, there may always be too small of an interest to make this a useful tool.&lt;/p&gt;
&lt;p&gt;Perhaps we should just stick to talking to each other for now.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakub Langr</dc:creator><pubDate>Mon, 14 Sep 2015 21:00:00 +0100</pubDate><guid>tag:,2015-09-14:gjp-part2.html</guid><category>prediction markets</category></item><item><title>Speaking at European Economic Congress 2015</title><link>/eec-2015.html</link><description>&lt;p&gt;I was recently invited to speak at European Economic Congress in Poland partially thanks to the fact that I was working at Aspen Institute Prague back in the summer of 2011. I was sort of skeptical, but when I saw the line-up for my panel all of that disappeared almost immediately. In fact, I was sort of expecting that with these sort of people why should anyone care what I had to say. &lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/panel.png" alt="Panel line up" align='center' /&gt;&lt;/p&gt;
&lt;p&gt;When I got to the airport, there was even a guy standing with my name (laminated!) on it waiting to escort me to the hotel. That freaked me out a little bit. But enough about this. Katowice was an interesting city: marred by Communist rule and somewhat this felt like a journey back in time -- recalling my childhood days in Prague. Poland was noticeably different from Czech Republic, but was eerily similar in many of the functionalist buildings and people's attitudes. &lt;/p&gt;
&lt;p&gt;So before delving into the trouble of entrepreneurship, I would like to address one thing that highly bothered me. After &lt;a href="/web-summit-dublin-14.html"&gt;Web Summit Dublin (a tech conference)&lt;/a&gt;, I was sort of expecting that I would be moving into a less male dominated space. Unfortunately, I was proved wrong. The ratio of men to women was highly disproportional (in favor of men, obviously) and in tech I at the very least think that there are reasonable arguments--whether or not they are true is beyond my knowledge of sociology or neuroscience--why this is not due to some systematic bias or lack of meritocracy. In business, there is just simply no excuse. But look at the pictures to see how strong the disbalance there is. In fact, Aspen Institute Prague did probably the best out of all those concerned--half of the team (including the operating boss) were women. But it gets worse: almost all of people in the promotional stalls and serving food were women. Almost model-like, made to look pretty at the stalls to attract the males to notice their company as if women had no other role. Quite disturbing. &lt;/p&gt;
&lt;p&gt;I think especially in Central and Eastern Europe where women have so much to contribute in the business world. I think that this region is missing out on a lot: not only a lot of talent, but also a different a bit softer and smarter approach would surely benefit the business performance of all these countries. (The fact that it also is probably a lot nicer to work/live in such an environment.) I know that I probably should not speak badly of the organizers given that they have paid for me to be there, but I think an international conference should be the first to push forth such an agenda. I do not want to seem ungrateful, but the contrast was just too stark and if the conference wants to aspire to be a truly European Economic Congress, it should aspire to also inspire a positive change in the society.&lt;/p&gt;
&lt;p&gt;&lt;img src='...' alt='Conference' /&gt;&lt;/p&gt;
&lt;p&gt;I am ending the rant now. The conference itself was held in a fabulous newly built Conference Center in the middle of Katowice. The conference was started off by the then President of Poland Bronis≈Çaw Komorowski. Despite not being explicitly on the agenda, he started discussing the issue of entrepreneurship quite a lot: the issue of retaining talent, attracting investors and so on. Although there were no concrete plans, I still appreciated this as a very important signal as well as the recognition that entrepreneurship is hard and if we want to succeed we must embrace failure. &lt;/p&gt;
&lt;p&gt;PICS!&lt;/p&gt;
&lt;p&gt;All of these notions were then repeated during my panel discussion and I even got a few shout-outs from others such as " As the gentleman on the far-right [of the panel] noted--without alluding to his political views--the young need to be willing to fail", as mentioned by the German ambassador. Though I was the only one to laugh at that remark, which was quite embarrassing. &lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakub Langr</dc:creator><pubDate>Tue, 30 Jun 2015 21:00:00 +0100</pubDate><guid>tag:,2015-06-30:eec-2015.html</guid><category>entrepreneurship</category></item><item><title>On MOOCs: Projects, Practice and Perspective</title><link>/moocs-part1.html</link><description>&lt;p&gt;It has been quite a while since I started my first MOOC at Coursera. I think now is the time to reflect on the courses I have finished, what I have learned as well as what to recommend to my fellow MOOCers. I will try to broadly classify (and score, because if you are anything like me, you occasionally dislike the imprecision of natural language) the courses I have finished and then I will try to give my take on MOOCs in general.&lt;/p&gt;
&lt;h1&gt;1. Awesome Courses&lt;/h1&gt;
&lt;h2&gt;&lt;a href="https://www.coursera.org/course/sna"&gt;Social Network Analysis&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course by &lt;a href="http://www.ladamic.com/"&gt;Lada Adamic&lt;/a&gt; was definitely one of the most awesome courses regardless of platform, country or institution that I have been involved in. Not only was Lada willing to have Google Hangout sessions with the course participants, but the course was excellently done: we have worked with &lt;a href="http://gephi.github.io/"&gt;Gephi&lt;/a&gt;, programmed in &lt;a href="https://ccl.northwestern.edu/netlogo/"&gt;NetLogo&lt;/a&gt; and used the &lt;a href="http://cran.r-project.org/web/packages/sna/sna.pdf"&gt;R SNA package&lt;/a&gt;(or at least I did in my projects). The course was a great balance of (social) network analysis, problem sets and optional programming assignments. You can view mine &lt;a href="https://dl.dropboxusercontent.com/u/30848031/US_Contributions.pdf"&gt;here&lt;/a&gt; (though bear in mind, I have done almost 2 years ago so it is not something I am particularly proud of). &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 10/10&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; R, Gephi, NetLogo, different metrics characterizing a graph&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://www.coursera.org/course/dataanalysis"&gt;Data Analysis&lt;/a&gt; and &lt;a href="https://www.coursera.org/course/compdata"&gt;Computing for Data Analysis&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Long before Coursera introduced the 'Data Science specialization' (that in my opinion seems way too superficial), Coursera was offering these two amazing Courses that together were actually undiluted first year graduate bioinformatics courses for students at Johns Hopkins University. The problem with a lot of the later MOOCs is that they were starting to get too simple to actually teach me anything and so the pool of people who was actually taking these courses was a lot worse. I think the latter is also an issue, because half of the learning experience is the community. Like the people putting interesting thoughts on the forums or the moderators (or in this case, the community itself) trying to prevent cheating (mostly unintentional, I hope, why else would you do a MOOC?) and so on. I have been taking this courses with statistics PhDs and other people with amazing insights and experience and I think that is probably why the learning experience was so amazing and all the four projects including &lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/Cellphone_data_Prediction.pdf"&gt;the final one&lt;/a&gt; were something that gave me a solid grounding for the Social Network Analysis MOOC to use R as well as for my &lt;a href="http://goo.gl/sEUFMa"&gt;internship in the summer of 2013&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 9/10&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; Through exploration of R basics, statistics, basic machine learning, data preparation&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://www.edx.org/course/introduction-probability-science-mitx-6-041x-0#.VMPxF4ptN5Q"&gt;Science of Uncertainty, Introduction to Probability&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course was amazing, but also &lt;strong&gt;very&lt;/strong&gt; hard. This is the undiluted MIT 6.041 course. The commitment from the teaching staff of MIT (including the professor &lt;a href="http://www.mit.edu/~jnt/home.html"&gt;John Tsitsiklis&lt;/a&gt;) was incredible. Generally, I got a great answer for any of my questions in a shorter period of time then most of my professors at my home institution. The treatment was very rigorous that keeping up with the Oxford workload while doing this 12 week course proved quite difficult. But it was so much more rewarding to see the certificate of completion afterwards.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 10/10&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; Probability theory, Statistics, Inference &lt;/p&gt;
&lt;h2&gt;&lt;a href="https://www.coursera.org/course/ml"&gt;Machine Learning&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Ah yes, this is where it all started. I had to, of course, eventually finish this course. Andrew Ng (my personal hero) created this course back in April 2012 and I believe it might be now in its 10th iteration. This course will give you a taster of Support Vector Machines, Recommender Systems, Artificial Neural Networks (basis for &lt;a href="http://en.wikipedia.org/wiki/Deep_learning"&gt;Deep Learning&lt;/a&gt;) and many others. The awesome thing about this course was that it abstracts &lt;em&gt;everything else&lt;/em&gt; apart from the ML algorithms to a package that you download so all you need to write is the machine learning algorithm. This means that this course is a mere introduction to machine learning and this alone cannot be considered to give you enough knowledge to actually go out and program some of them in production. This course was just so much fun, because of all the cool stuff that you write that I still have to give it 10/10. Plus, in the right data science tradition, this course has been continuously improved for each iteration.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 10/10&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; Machine Learning, MATLAB, Statistics&lt;/p&gt;
&lt;h1&gt;2. Great Courses&lt;/h1&gt;
&lt;h2&gt;&lt;a href="https://www.edx.org/course/introduction-computational-thinking-data-mitx-6-00-2x-0"&gt;Computational Thinking and Data Science&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course was a great application of Object-Oriented Programming and simulations. I have to say I have gotten so much support on the forums it was incredible. (I do not recall, however, whether this was mostly staff or other students. Either way, great answers.) I think that the course, however, was too short and might have been more rigorous. (Though I do understand this was only a half an MIT course and probably simplified.) But I just admire professor Guttag as a person for being one of the first to get on board with MOOCs. This course was also a very different take on data science from the usual approach, as here you focus on simulations--e.g. behavior of different virus populations based on applications of different drugs/medicines and the genetically inherited (hence the OOP design) resistance to different active components of these drugs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 8/10 &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; OOP, Simulations, Stochastic Algorithm Testing&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://www.udacity.com/course/cs215"&gt;Udacity Algorithms&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I finished this course before Udacity changed their business model from offering free courses with no deadlines to one where they only offer paid courses (though the material is still free, but you cannot get a certificate). This course was quite hard and the support was sparse (for a MOOC). But this meant that I just had to spend a bit more time thinking about the problem, which was probably helpful in the end to my general CS skills. I think that all the concepts were quite well explained and overall I think that there was sufficient practice to really understand the material. Though there was not so much of a 'course feel', which there was in both Coursera and EdX. But despite this, they recorded &lt;a href="https://www.youtube.com/watch?v=stdG3BGmhqo"&gt;probably the most awesome CS theory song in existence&lt;/a&gt;, so I cannot really question anything about this course. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 8/10 &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; Algorithms, Data Structures, Social Network Computation &lt;/p&gt;
&lt;h2&gt;&lt;a href="https://www.udacity.com/course/ud032"&gt;Udacity Data Wrangling with MongoDB&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course is a bit different from all the others: you can either take it for free (but no certificate at the end) or you can pay $200 for each month and have a personal coach, human-verified project at the end and get that certificate. Partially, because I wanted to evaluate Udacity's new business model and partially because I knew that data wrangling is a huge part of data science, I finished this course in about month and a half. Surprisingly there is very little about MongoDB -- it is only introduced in the last 20% of the course, but that does not mean that the course does not teach you helpful skills. It does! Web scraping and XML parsing are definitely useful skills and I think that the course is appropriate in difficulty, though I think that it could be a bit harder at times to really force the students to organize their code well and debug more complex data cleaning parsers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 8/10&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned&lt;/strong&gt;: Website Scraping, Data Wrangling with Python and MongoDB&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://www.coursera.org/course/networksonline"&gt;Social and Economic Networks: Models and Analysis&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Normally economists (especially the really famous ones) are not too keen to join MOOCs, but that just makes &lt;a href="https://web.stanford.edu/~jacksonm"&gt;Matthew Jackson&lt;/a&gt; that much more awesome. This class was fun and allegedly a graduate level, though it must have been very diluted, because I found the material (although going to greater depth than the Michigan Course) quite easy. There was again some work with Gephi and this time even Pajek, though sadly no R. But I should note that there were more advanced versions of the course that one could participate in (sadly, with no recognition) that I wanted to participate in, but unfortunately I did not have the time. So I think potentially this could have been an 8/10.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 7/10 &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; More computational and mathematical methods for social network analysis&lt;/p&gt;
&lt;h2&gt;&lt;a href="http://online.stanford.edu/course/statistical-learning"&gt;Statistical Learning&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course covers an explanation of most of a recent book by Trevor Hastie, Robert Tibshirani and others: &lt;a href="http://www-bcf.usc.edu/~gareth/ISL/"&gt;An Introduction to Statistical Learning, with Applications in R&lt;/a&gt; and some of their more advanced book, &lt;a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/"&gt;Elements of Statistical Learning&lt;/a&gt;. This course is fun to take, though I mentioned 'explanation' for a reason. This course will provide you with a thorough explanation of fairly advanced statistical concepts, but definitely will not test you rigorously enough. Usually, especially if you buy the discounted versions of one of the books, you will get enough knowledge and training to apply some of these concepts sensibly. But you will still need to work hard to test yourself and to really probe the ideas with no assistance. Regardless of whether you do, the lectures are really fun to listen to and explain concepts very well.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 7/10 &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; Machine Learning, Intermediate Statistics, Computation&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://www.coursera.org/course/initprogjava"&gt;Introduction √† la programmation orient√©e objet (en Java)&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I think I pretty much took this course, because programming in English is too mainstream. But it was really nice to learn a language from 0 in a very organized environment. What I genuinely appreciate is the walk-throughs on how to set up the Java environment in Windows, Ubuntu and Mac. But what I think was by far the best thing about this course was that the actual instructors were &lt;em&gt;so commonly&lt;/em&gt; involved on the forums, helping people. Even I once received some help from one of the instructors, which was great. Coding-wise, the MOOC was quite simple, but I assume approximately on the same level every other intro course for non-CS majors would be. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; Java, French, Basic Data Structures&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 7/10&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://www.coursera.org/course/bigdata"&gt;IIT's Web Intelligence and Big Data&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course was quite fun and relatively easy to grasp. The concepts revolved around the mathematics (and some programming) of the Big Data technologies, as well as their (recent) history. The problem sets were well done, though sometimes seemed bit too shallow and I would appreciate a bit more programming. The programming assignments were great: tested a whole array of important skills and technologies, but were only three through the entire course. This course was allegedly supposed to be taken as a half-course by actual IIT engineers. I, however, seem quite skeptical of that, as it seemed a bit too easy if true. But generally quite fun and insightful. Though the MOOC seemed to be a bit mass produced with little involvement from the IIT staff after a while.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; Map-Reduce and other "big data algorithms" (locality sensitive hashing, page rank etc.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 7/10&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://www.coursera.org/course/introfinance"&gt;Introduction to Finance&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course was my first MOOC I finished so I still remember quite a lot the odd details, as well as some of the catch-phrases the professor was using ("It's not about finance, it's about love.") as well as the fact that people (probably still stuck in the school mentality), were trying to ease their way through the course. I actually learned a lot of interesting concepts I did not know. With this said, I started this course in June 2012, which is just two or three months after Coursera launched. But that meant that some aspects of the course were quite not ready. The platform was great, but I feel like courses tended to be a bit better structured in the later courses. But the fact that I was trying out the first iteration also meant that right now the course could be a 10/10.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; Basic accounting, basic financial modeling (but going beyond NPV etc.), Excel&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 7/10&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://www.coursera.org/course/getdata"&gt;Getting and Cleaning Data&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This course was by the same Jeffrey Leek and Roger Peng that I admired so much and it was part of the data science specialization. But it was just not nearly as good as the previous two. And because by this point I knew that data science is 90% data cleaning and 10% complaining about data cleaning (I think I used this as a joke somewhere, but it &lt;em&gt;might&lt;/em&gt; not be my line, but I could not find the original source.), I wanted to learn more about how to do it efficiently. I wanted to try out the new specialization that the company that I so love and admire was spearheading. But the course was quite short, and although overall well-done, it was just not a very transformative experience. I think that I also really knew about 95% of this course, so I did not even watch most the lectures. Next week I always dived in in hopes of learning something new. I think for a beginner it could be a decent course, but I am still not sure if I would pay $49 for it. Though I understand the tradeoff Coursera was facing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skills learned:&lt;/strong&gt; (potentially) Data wrangling, RegEx, &lt;code&gt;reshape&lt;/code&gt; and other useful packages.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Score&lt;/strong&gt;: 6/10&lt;/p&gt;
&lt;h1&gt;3. Good Courses&lt;/h1&gt;
&lt;p&gt;There good thing about the MOOCs is that if I don't like the course, the instruction seems crappy or I have hard time understanding the professors or I just do not like something, I can drop it. Moreover, there is so many great and awesome courses that I could not even do those that seemed 'good'--i.e. I would most likely like to take them if they were one part of the curriculum at my home institution. &lt;/p&gt;
&lt;h1&gt;Best practices&lt;/h1&gt;
&lt;p&gt;I think there are 3 key strategies to successfully finishing the MOOC. But the key insight is that most people who do not finish a MOOC usually do not finish it because of lack of time, not because of lack of aptitude. So lack of persistence is your key enemy. To crush your enemy, you have to:&lt;/p&gt;
&lt;h2&gt;1. Assess quickly the time commitment of a course.&lt;/h2&gt;
&lt;p&gt;I still remember that &lt;a href="https://class.stanford.edu/courses/Engineering/CVX101/Winter2014/about"&gt;convex optimization course&lt;/a&gt; by Stanford that I really wanted to take. But, alas, I could not. I did not have the time as I had a busy schedule &lt;em&gt;and&lt;/em&gt; I was doing another MOOC (or two?) at the time. I realized that this was a rigorous class that required substantial time commitment. But I needed to drop it, because if you do not take each commitment seriously, you will probably not finish any of them.&lt;/p&gt;
&lt;h2&gt;2. Honor your commitments&lt;/h2&gt;
&lt;p&gt;Meaning also that you should immediately unenroll from the courses you know you cannot finish. This will hopefully also give you the respect towards your commitment that you will also finish the ones you have elected to keep.&lt;/p&gt;
&lt;h2&gt;3. Commit to deadlines, minimum benchmarks&lt;/h2&gt;
&lt;p&gt;There is a reason why I only finished one free course on Udacity: because there are no deadlines (well, until they introduced the payment by the month). These help you get stuff done, because now you have to or all (or at least something) is lost. All major platforms have it now, so please use it.&lt;/p&gt;
&lt;p&gt;Benchmarks are also very helpful: there were courses (like both of the SNA ones) where I knew I wanted a distinction, because I wanted to know the stuff &lt;em&gt;well&lt;/em&gt;. Then there were courses, where I just wanted a brief overview so I only watched lectures (not listed, because I technically, haven't finished them). But decide quickly what your goals are and then follow them.&lt;/p&gt;
&lt;p&gt;I would also love to do a general post on MOOCs, but I think things are best kept separate. &lt;!-- Generally, I think MOOCs will fundamentally change the nature of education (for reasons that deserve a separate post), _provided_ that they manage to meaningfully integrate themselves to people's lives. We could already see many interesting initiatives like the one by &lt;a href="https://www.edsurge.com/n/2014-11-19-free-coursera-pd-thanks-to-the-president"&gt;Obama for teachers for their professional development&lt;/a&gt;. But currently MOOCs are mostly a domain of people who are happy to sacrifice some degree of social life for learning (totally worth it). Though I do not doubt there are exceptions, it seems that most people I know (and online statistics confirm this) are too busy to actually finish the courses.  --&gt;&lt;/p&gt;
&lt;p&gt;Anyway, hope this was helpful. As always, I would welcome any reaction. Get in touch!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakub Langr</dc:creator><pubDate>Fri, 23 Jan 2015 21:00:00 +0000</pubDate><guid>tag:,2015-01-23:moocs-part1.html</guid><category>R</category><category>education</category><category>python</category><category>reviews</category></item><item><title>On Randomness in (Social) Science</title><link>/underspecification-socsci.html</link><description>&lt;p&gt;A while back I was mentioning &lt;a href="/hello-world.html"&gt;how I was confused by the randomness as an emergent property of human systems&lt;/a&gt;, and so I have been giving this some thought, which I thought I might share with the world. The underlying problem always has been why is &lt;a href="http://plato.stanford.edu/entries/properties-emergent/"&gt;emergent&lt;/a&gt; randomness a good model of human behavior. At some level, we understand that our actions are &lt;a href="http://en.wikipedia.org/wiki/Determinism"&gt;deterministic&lt;/a&gt; at least on above-quantum level and I really dare not make any statements about the quantum nature of the universe. &lt;/p&gt;
&lt;p&gt;Before I start the discussion it is worth pointing out that I will try to make this as intuitive as possible, but some math will have to be involved, though I tried to make it so that it is not necessary to understand everything to really understand the point of this article. It was included to make the reasoning a bit easier. At the same time I am making some imprecise statements for the sake of understanding, but if you feel I might be leading people astray, feel free to drop me a line.&lt;/p&gt;
&lt;p&gt;The very definition of randomness is lack of predictability. That seems almost circular, but first thing to note here is that does not mean that all outcomes are equally likely. Think about a pair of dice, and our random variable ("what we measure") as the sum of the two rolls. Here there are seven has six possible combinations (6+1,5+2,3+4,4+3,2+5,1+6), giving us approximately normal distribution centered at seven:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;COUNT           NUMBER OF       PROBABILITY
                COMBINATIONS    
2               1               2.78%
3               2               5.56%
4               3               8.33%
5               4               11.11%
6               5               13.89%
7               6               16.67%
8               5               13.89%
9               4               11.11%
10              3               8.33%
11              2               5.56%
12              1               2.78%
Total           36               100%
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A better definition of randomness is that given an infinite amount of trials of random variable &lt;span class="math"&gt;\(Y\)&lt;/span&gt;, we get the true distribution where the outcome of the next realization of said random variable is still unpredictable. So say you are throwing some dice in a casino and you are trying to figure out what is the bet that makes sense where in this odd casino you are meant to bet on the sum of the two dice. The number actually rolled will be a realization  (what you actually rolled) of &lt;span class="math"&gt;\(Y\)&lt;/span&gt; at time &lt;span class="math"&gt;\(t\)&lt;/span&gt;. Any given roll will be unpredictable -- otherwise you could easily bet on it -- but it is deterministic -- i.e. if at the point of the throw you had a lot of time and all the laws of physics you could say with 100% certainty what the roll it is going to be. Yet right now, you do not know. However, that does not mean that it does not follow a certain distribution even though it is unpredictable. &lt;/p&gt;
&lt;p&gt;Now there is no doubt that if you come across any given pair of dice and you are asked what do you think the next number will be 7 should be your top choice. (Because it minimizes likely how far off the true number you are likely to be, both because it is in the middle and because it is most likely.) That is what can be thought of as expectation. However, generally the expectation lies in the middle of the distribution, but need not be the most common value. This becomes more obvious if we look at the formula for expectation. It is basically a weighted average of the value (&lt;span class="math"&gt;\(y\)&lt;/span&gt;) and the frequency (&lt;span class="math"&gt;\(f(y)\)&lt;/span&gt;). (Where &lt;span class="math"&gt;\(a\)&lt;/span&gt; and &lt;span class="math"&gt;\(b\)&lt;/span&gt; are the boundary points.)&lt;/p&gt;
&lt;p&gt;
&lt;div class="math"&gt;$$
E[Y] = \sum_{a=2}^{b=12} y f(y) \,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,  \,\,\,\,\,\,\,\,\,
\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,\,
$$&lt;/div&gt;
&lt;/p&gt;
&lt;p&gt;In theory, we can even have a distribution where the expected value is impossible, such as the one below: (for a concrete example imagine student's ratings of a &lt;em&gt;really&lt;/em&gt; controversial class on a scale from -15 to +15, where the two groups are equally split and the average rating is about zero)&lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/download.png" alt="Distribution" align="center" style="width: 620px;"/&gt;&lt;/p&gt;
&lt;p&gt;If you look at the formula for expectation above it is all very nice and mathematical. We have our best guess that makes sense, but is far from guaranteeing that we are actually walk back home with a lot of money. But what if you could observe rolls of two dice would they be perfectly distributed according to the distribution that we have specified? Well, no. Dicemakers probably tried to make them as balanced as possible, but probably every pair of dice has certain numbers that will come less or more commonly than simple combinatorics would suggest. This deviations might be due to tiny imperfections on the table, the dice themselves or many other factors. If you find statistically significant relationships, we might be able to derive a marginally better model. But it is only going to do as well as the strength of relationships. Moreover, if we find these associations and do not really understand why -- e.g. we just observe, they might backfire, because if maybe we found some irregularities on the table and then we start throwing on other parts of the table, we will start losing more. Our model did not generalize "out of sample" (on what we did not observe) well.&lt;/p&gt;
&lt;p&gt;Now bring this back to social science. Some people choose to think of the economy as some sort of machine, which suggests determinism. Let's accept that for a second. &lt;/p&gt;
&lt;p&gt;Even if we do we have two problems: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The underlying nature of the system keeps on changing. Sure, economy &lt;em&gt;can&lt;/em&gt; be a machine, but it will be a different machine in March 2014 and different in April. &lt;/li&gt;
&lt;li&gt;It does not actually explain why there is any randomness. A machine is deterministic, so shouldn't our predictions be too? It turns out that it is the emergent property (or rather the fact that we have incomplete information) that makes it random. So yes, the world may be deterministic but we need a lot more information that we ever have. Hence we are trying to abstract models that capture the key information. So in our dice example we can notice that the side with one is heavier than the others and hence might come up marginally less often and even though the dice roll is always deterministic, the best heuristic, if we cannot exactly calculate everything, is to use the base rate (how often does 7 naturally occur) plus whatever extra information we may have (heavier sides?).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But randomness only really makes sense if we are actually trying to predict something. We are essentially saying that there is a part that our model (the base rate and extra information together) can predict [1] and a part that our model cannot explain -- i.e. the error term [2]. Basically whenever we don't get our prediction exactly right we get an error -- the difference between actual and expected value. So what we are basically saying is that at this level we can only explain so much and the predicted value is our best guess. That is, after all, what we are doing intuitively with the dice as well: we all intuitively know that predicting always that the outcome is going to be 3 is not a good strategy, unless we know that the dice are biased towards them.&lt;/p&gt;
&lt;p&gt;So really, this problem is not unique to social science, but rather inference in general. Because all of the extra information we have probably included in our prediction. Think about predicting rain: to have rain you need clouds, hence if there is a huge black cloud over your head your prediction with this extra information will already be say 90%, but that is only because we have already built the model (we know) that if there's a could over our heads it it is likely to rain. The fact that it does was not a trivial insight at some point. This is what we are doing in science, except with much more difficult concepts. Hence, randomness has to be an emergent property of &lt;em&gt;any&lt;/em&gt; predictive model with incomplete information. And since we make predictions so often in every science and the error term has to be random (otherwise we could easily figure out a better model), which is why all the good models of complex behavior have to have a random part. But always keep in mind that the distribution of errors can vary, but there is always going to be a random part by definition unless we know the true model (i.e. we have complete information).&lt;/p&gt;
&lt;p&gt;I hope that this was helpful and that you know at least sort of understand why randomness is not a property of human systems, but of prediction with incomplete information and that there are different forms that randomness can put on. But I would love to hear your thoughts and feedback, let me know!&lt;/p&gt;
&lt;p&gt;[1] usually denoted as &lt;span class="math"&gt;\(E(Y | {\bf X } )\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;[2] usually denoted as &lt;span class="math"&gt;\( \epsilon \sim \mathcal{N}(0,1)\)&lt;/span&gt;, though it can be distributed according to a wide variety of distributions.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakub Langr</dc:creator><pubDate>Sat, 06 Dec 2014 04:00:00 +0000</pubDate><guid>tag:,2014-12-06:underspecification-socsci.html</guid><category>technical</category><category>social science</category></item><item><title>Web Summit Dublin 2014</title><link>/web-summit-dublin-14.html</link><description>&lt;p&gt;So I rarely get this emotional about an event, but Web Summit definitely is an experience I will never forget. I was incredibly lucky to be &lt;a href="http://blog.websummit.net/student-blog-announcement/"&gt;selected as one of the 22 initial Student Scholars&lt;/a&gt; to give free attendance to Web Summit Dublin 2014. When I was applying little did I know how awesome this experience will be. When they told us that we were selected out of 6,600 applicants (final figure was apparently at 15,000 for all rounds), I was a bit skeptical. When I saw the list of people I was supposed to be going to the Summit with, my only thought was: "I don't belong here".&lt;/p&gt;
&lt;p&gt;Once it got to term time I did not quite have the brain capacity to worry about this. But somehow, when it eventually got to the Summit itself, I was not sure what to expect. I did not know anyone from the group of scholars and even the arrangements from the Summit with regards to our arrival were very much in the start up mentality -- hectic and required some figuring out. (That is not to blame the team at all, everything that was supposed to work, worked.)&lt;/p&gt;
&lt;p&gt;My 2 am bus ride to catch my 6 am flight was somewhat annoying, but hey, if it is to go such an amazing event, why not. Actually, it feels kind of boring to travel during regular hours. Already on the bus to the hotel, I met up with two other scholars and I immediately felt at home: super interesting people one of whom went to business school the other to medical school. &lt;/p&gt;
&lt;p&gt;On the first day we did some serious sightseeing with those who arrived a bit early, as the first event was in the evening. Some people really wanted to go on the Hop On, Hop Off bus tour, which I though was quite touristy, but felt like I should try it.&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-03%2013.55.12.jpg" target="_blank"&gt; &lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-03%2013.55.12.jpg" alt="Excited tourists" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;td&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-03%2013.10.56.jpg" target="_blank"&gt; &lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-03%2013.10.56.jpg" alt="Yay bus tour!" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;Definitely no regrets, we got to see a lot of Dublin that we normally would not have any time to see. Then it was time for our first pub crawl. These were integrated into Web Summit and there was even a special pub crawl for the scholars with some of the more successful companies at the Summit. &lt;/p&gt;
&lt;p&gt;It comes as no surprise that the networking was awesome. But what is far more important: it felt really natural. I always hated networking for the sake of networking. I wanted to meet new people and make friends. And if they happen to be useful connections, great. If not, it's still a win, you have an awesome friend. That is really what made it so easy.&lt;/p&gt;
&lt;p&gt;Then we were escorted to dinner at Guinness factory, where on the top floor some speakers (Drew Houston!!!) along with scholars were all having dinner. I think I even shook Drew's hand so that already made me quite happy. Plus I just casually happened to speak to the CEO of Idea Paint. Incredible. &lt;/p&gt;
&lt;p&gt;After the dinner we moved to the Night Summit, which was a street rented out by Web Summit so that the attendees of the Summit can wind down and talk to each other over a pint. I think I came home at about 2 or 3 am. &lt;/p&gt;
&lt;table&gt;&lt;tr&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/IMAG0803.jpg" target="_blank"&gt; &lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/IMAG0803.jpg" alt="Guiness Dinner with Drew et al" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;td&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-04%2008.42.05.jpg" target="_blank"&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-04%2008.42.05.jpg" alt="Yay start up exhibition hall!" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;The next day, it was start of the Summit's main part, which was absolutely &lt;em&gt;mind-blowing&lt;/em&gt;. So many awesome start-ups to talk to, the picture above only barely describe my excitement when I saw the main exhibition hall. But also, there were about seven stages that were full of the super stars of tech community: Tim O'Reilly (sorry for the bad picture), Peter Thiel (I missed the book signing :( ), GitHub CTO and many others. &lt;/p&gt;
&lt;table&gt;&lt;tr&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-06%2013.23.04.jpg" target="_blank"&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-06%2013.23.04.jpg" alt="Tim O'Reilly" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;td&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-06%2016.35.56.jpg" target="_blank"&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-06%2016.35.56.jpg" alt="Peter Thiel" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;The Night Summit made me happy to be missing sleep again. But we went to have drinks at the Lord Mayor of Dublin, which was amazing. Though at that time I was already spoiled, as earlier in the day we saw an opening of NASDAQ from Dublin by the Prime Minister of Ireland.&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-04%2014.21.16.jpg" source="_blank"&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-04%2014.21.16.jpg" alt="NASDAQ Opening. NBD." align="right" style="width: 310px;"/&gt;&lt;td&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-04%2018.18.52.jpg" source="_blank"&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-04%2018.18.52.jpg" alt="Lord Mayor of Dublin" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;Even the last day had so much to offer: Bono, Dana Burnetti and many others. Paddy Cosgrave the main organizer handled everything excellently, though he was pointing out the issues with WiFi and how that is not really their fault a bit too often. (Though to me that did not pose a problem.)&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-06%2017.19.28.jpg" target="_blank"&gt; &lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-06%2017.19.28.jpg" alt="Bono et al" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;td&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-06%2017.01.49.jpg" target="_blank"&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-06%2017.01.49.jpg" alt="Dana Burnetti" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;This was also a week full of incredible occurrences: I randomly happened to speak to the founder of Twitch, without even knowing. One other scholar was just finishing his homework in the lobby of our hotel and happened to stumble upon Dave McClure -- the founder of 500 Start-ups -- the person who just a day earlier said on stage: "If you are going to pitch to my f*cking face [without being invited to], I am not going to listen to you". But at this time Dave was trying to set-up Node.js (&lt;a href="hack-zurich-14.html"&gt;framework that we all love&lt;/a&gt;) and my fellow scholar who happened to know Node got an internship offer for this one act of kindness.&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-05%2022.33.40.jpg" target="_blank"&gt; &lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-05%2022.33.40.jpg" alt="The Kooks!" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;td&gt;
    &lt;td&gt;&lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-06%2014.51.41.jpg" target="_blank"&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/2014-11-06%2014.51.41.jpg" alt="Dave McClure" align="right" style="width: 310px;"/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;Other story that I still struggle to believe is that the Kooks happened to be playing without many people even knowing about it in one of the Night Summit venues. I only found out about that less than an hour before the show from a friend of mine when we just happened to be randomly talking about what we are doing tonight. He forwarded me an email (that already was forwarded at least 5 times) that was saying that Kooks will be playing in one of the venues. I don't think that it was that the organizers were trying to hide this event -- it's just that so much else awesome was going on.&lt;/p&gt;
&lt;p&gt;Overall, words cannot describe how amazing this event was. I have learned so much from other Summit attendees, especially the scholars. I have had many interesting, fun and inspiring conversations. So if you are still in university, keep an eye out! Organizers promised they will do it again next year and you don't want to miss that!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakub Langr</dc:creator><pubDate>Fri, 14 Nov 2014 20:00:00 +0000</pubDate><guid>tag:,2014-11-14:web-summit-dublin-14.html</guid><category>Web Summit</category><category>non-technical</category><category>Dublin</category><category>Start-up</category></item><item><title>#hackZurich 2014: A hackhathon to remember</title><link>/hack-zurich-14.html</link><description>&lt;p&gt;When you work with a lot of engineers, you start to envy all those cool personal projects they have and all those cryptic plug-ins they know and have mastered. A lot of this happened at Hackathons. So I wanted to try one myself to have a proper experience of trying to code up an app from scratch in less than 42 hours. So when I found about hackZurich, I was sold.&lt;/p&gt;
&lt;p&gt;In all seriousness, I was. The hackathon looked &lt;em&gt;amazing&lt;/em&gt;: more sponsors than any society or event I've seen. Cool APIs opened only for hackZurich and &lt;em&gt;they even reimbursed most of travel costs.&lt;/em&gt; The only annoying this was that this event was happening around exam time. But seeing as I am writing elaborate odes on this, you can probably guess what I chose. &lt;/p&gt;
&lt;p&gt;Except it was not that easy: I knew I wanted to go to a hackathon, except I've never been before. And there was an application process. Realistically, I am not sure how selective it was, but there was a cap of 300 people and given that there are always freebies and free food, I think hackathons can be quite appealing.... at least for me. But I mean we had to sleep on the ground, on the tables and on our bags and some people did not even have sleeping bags. I do not want it to sounds like I am complaining. No one actually slept a whole lot (I slept about 4 hours first night and one hour the second) so no one really cared. I found my own non-lit corridor and slept on the floor, because I really need quiet environment. But hey! It was a fun experience and I was worried I am getting a little snobby. &lt;/p&gt;
&lt;p&gt;So hacking! We had about 30-40 hours to code an app on any topic, but noting of course that some companies gave us exclusive (and some promoted only their existing) &lt;a href="http://en.wikipedia.org/wiki/Application_programming_interface"&gt;APIs&lt;/a&gt; for us to try something new. Except, as a person knowledgeable mostly of the data science stack, I soon realized that I will need to go back to coding some web apps to have something to show. That, however, was a problem, because I have not coded up a web app in over a year. So I was afraid that I simply may not be up to the challenge skill-set wise. &lt;/p&gt;
&lt;p&gt;Fortunately, organizers created a Facebook group for people to get together and discuss their preliminary ideas, but standard hackathon rules apply: no code before the official kick-off. So I joined the group and was discussing ideas with people and was quite happy to see that a lot of people were not extremely concerned about the lack of specific skills. &lt;/p&gt;
&lt;p&gt;Despite this, I was quite nervous, because this was my first hackathon and I was not quite sure what to expect. I teamed up with a friend of mine, because I figured going to a hackathon in a different country in a busy period and coding in technologies I have never mastered and even the little experience I had was long time ago, it is going to be challenging as is.&lt;/p&gt;
&lt;p&gt;We roughly discussed the idea beforehand, but as my head was full of Mathematical Methods exam that I was supposed to be taking the day before leaving, I did not quite do justice to preparation as a lot of Node JS I needed to refresh on the go and that slowed me down considerably. But let's not jump the gun. &lt;/p&gt;
&lt;p&gt;After finishing my exam on Thursday and doing chores until my departure from Oxford shortly after noon, I was quite freaked out: I still haven't really unpacked and I was already going places. But the trip was cool: I was flying from London City Airport for the first time, which was quite exiting. &lt;/p&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/IMAG0752.jpg" alt="Destination: #hackZurich" align="center" style="width: 620px;"/&gt;&lt;/p&gt;
&lt;p&gt;Despite not knowing anything about Zurich, I perfectly navigated and caught the pre-planned (from about a week ago!) train straight to the hackathon venue, which made my day. Hackathon itself was held at a &lt;a href="http://technopark.ch"&gt;TechnoPark&lt;/a&gt;, which seemed to be a quite modern open space for start-ups and small companies. Upon arrival, I got my badge and bag of goodies that I still haven't fully explored, because there's just &lt;em&gt;so much stuff.&lt;/em&gt;  (Yay!) &lt;/p&gt;
&lt;p&gt;Anyway, I unfortunately missed the opening ceremony, but I arrived just in time for the pretty cool workshops: Evernote had an introduction to their APIs and Software Development Kits and then I went to presentation about Google wearables. Where Google-certified android master (presenter) sent a guy who wanted to go to the Apple workshop to the 6th floor (where there was no workshop) and after the poor guy left, he said: "Ooops, I must have been using Apple Maps." The sass is strong with this one. &lt;/p&gt;
&lt;p&gt;After the workshops, &lt;strong&gt;let the hacking commence.&lt;/strong&gt; My friend and I were using MEAN stack and &lt;a href="http://d3js.org/"&gt;D3.JS&lt;/a&gt; to build a budget tracking app. That is &lt;a href="http://mongodb.org"&gt;MongoDB&lt;/a&gt;, &lt;a href="http://expressjs.com/"&gt;Express.JS&lt;/a&gt;, &lt;a href="https://angularjs.org/"&gt;Angular.JS&lt;/a&gt; and &lt;a href="http://nodejs.org/"&gt;Node.JS&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It was challenging doing all this coding, but I have to say, quite fun. The atmosphere was amazing and a ton of caffeinated drinks around. Here and there was an occasional food shortage, but hey: free food. After the kick-off people, obviously, started coding. And they coded... until 430 am. At which point I decided that it &lt;em&gt;might&lt;/em&gt; be a good idea to get some rest and so I finally managed to find a nice hallway to sleep in by about 5 am. &lt;/p&gt;
&lt;p&gt;&lt;img src="https://scontent-a.xx.fbcdn.net/hphotos-xpa1/v/t1.0-9/s720x720/10689898_10203303761088371_4719824619037743016_n.jpg?oh=e9683900216a3692b0ca916a2be2f27c&amp;oe=54AE910E" align="center" alt="4 am #hackZurich" style="width: 620px;" /&gt;&lt;/p&gt;
&lt;p&gt;You think that was bad? Check out where some of these poor souls have been sleeping:&lt;/p&gt;
&lt;p&gt;&lt;img src="https://pbs.twimg.com/media/BztdrGDCEAMmoY6.jpg:large" align="center" style="width: 620px;" alt="People sleeping on the floor."&gt;&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;
    &lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/IMAG0772.jpg" alt="Finders, sleepers" align="right" style="width: 310px;"/&gt;&lt;td&gt;
    &lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/IMAG0777.jpg" alt="Finders, sleepers" align="right" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;Despite my effort to stow myself away I was woken up several times by people sneaking through my corridor to find an even more obscure corridor to sleep in, which sometimes looked quite weird, not to mention awkward, especially if you make eye contact. Anyways, I woke up by 8:30 am to sounds of some radio (&lt;strong&gt;rage&lt;/strong&gt;) and since I was up and I got breakfast and started working. Morning was quite productive, but after a while we got quite tired and hungry and so we went on a walking tour of Zurich that organizers kindly organized for us.&lt;/p&gt;
&lt;table&gt;&lt;tr&gt;
    &lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/IMAG0762.jpg" alt="Finders, sleepers" align="right" style="width: 310px;"/&gt;&lt;td&gt;1
    &lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/IMAG0765.jpg" alt="Finders, sleepers" align="right" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;
    &lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/IMAG0767.jpg" alt="Finders, sleepers" align="right" style="width: 310px;"/&gt;&lt;td&gt;1
    &lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/IMAG0771.jpg" alt="Finders, sleepers" align="right" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;I have to say Zurich is quite an amazing city. It has a very picturesque, small-town feel and it really feels too fairly-taily to be true.  &lt;br&gt;&lt;/p&gt;
&lt;p&gt;The next night was a bit more rough as we had issues with our database and Node.JS not being synchronized, which is one of the pains of working with asynchronous stacks, which took us quite a long time to fix. I stopped working at around 4:30 and got up at 6 something to go finish our app before the 930 am deadline.  &lt;br&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, our app did not make it into finals--as those were only for 1/4 of the participants--but this hackathon was definitely awesome. Would do again.  &lt;br&gt;&lt;/p&gt;
&lt;p&gt;Seeing as I yammered for too long again, I will leave it at that, but I will be back for more!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakub Langr</dc:creator><pubDate>Sun, 12 Oct 2014 20:00:00 +0100</pubDate><guid>tag:,2014-10-12:hack-zurich-14.html</guid><category>hackathon</category><category>non-technical</category></item><item><title>Tracking the CrISIS in Syria</title><link>/tracking-crisis.html</link><description>&lt;p&gt;If you are interested more in the analysis of the conflict from a quantitative persective and not so much in the methodology, you &lt;a href='#explore'&gt; can jump straight there.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As I was working as a contractor this summer, I came across a very interesting project called &lt;a href="http://www.gdeltproject.org/"&gt;GDELT&lt;/a&gt; -- Global Database of Events, Language and Tone. This project I think is best described by the official website statement: "GDELT Project monitors the world's broadcast, print, and web news from nearly every corner of every country in over 100 languages and identifies the people, locations, organizations, counts, themes, sources, and events driving our global society every second of every day, creating a free open platform for computing on the entire world."&lt;/p&gt;
&lt;p&gt;In addition to that, as a part of &lt;a href="../hello-world.html"&gt;Good Judgement Project&lt;/a&gt;, I was made to forecast on Syria and ISIS' actions. As I was going through the articles describing what is happening in Syria, I became to wonder: what is the bigger picture? To what extent is this hype all just because &lt;strong&gt;now&lt;/strong&gt; ISIS is the headline-grabber in the West? (But of course, no one cares until it becomes a story in the public consciousness.) That's when GDELT comes into the picture. I wanted to try it as I came across it, but since I was finishing my data science project, I did not quite have the time. I was awe-struck by the complexity and potential of it so I knew I wanted to give a go. I have not really used R all that extensively in about a year since my internship, but I am not afraid of large analytics, so I decided to refresh those skills.&lt;/p&gt;
&lt;p&gt;Fortunately, Google was so nice as to host this almost 100 GB dataset on &lt;a href="http://googlecloudplatform.blogspot.cz/2014/05/worlds-largest-event-dataset-now-publicly-available-in-google-bigquery.html"&gt;its cloud for free&lt;/a&gt;, for which I love Google. Not only that, but Google also loaded this dataset so that it can be queried using &lt;a href="http://en.wikipedia.org/wiki/BigQuertracky"&gt;BigQuery&lt;/a&gt; using public-facing APIs or a web interface. We can then query GDELT using SQL-like language as shown below and subsequently export the dataset as a CSV:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;gdelt&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;bq&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="k"&gt;full&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;events&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; 
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MonthYear&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="mi"&gt;201303&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="k"&gt;Year&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="mi"&gt;2015&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;NumSources&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;GoldsteinScale&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;AND&lt;/span&gt;
&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;Actor1Geo_CountryCode&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;SY&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Actor1Code&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;IMG&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;Actor1Code&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;REB&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Actor2Geo_CountryCode&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;SY&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Actor2Code&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;IMG&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="n"&gt;Actor2Code&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="ss"&gt;&amp;quot;REB&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="k"&gt;Year&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(For those interested, I include a smaller version of the dataset I was working with after exporting from GDELT &lt;a href="https://dl.dropboxusercontent.com/u/30848031/blog/sample.csv"&gt;here&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;The assumption of this endeavor is that if I include non-English media (and perhaps the less main-stream ones too) by using GDELT's information rather than Google, which will always give me traditional sources, I can get a better sense of what is going on. Thanks to the the law of large numbers, I should not get too many false positives from spurious sources, so my overall analysis should remain robust and even more objective than relying on sources such as CNN or BBC alone. One additional advantage GDELT has is that it is updated every 24 hours. In theory, this analysis could be automated so that it updates itself every 24 hours. (Actually, it should not be &lt;em&gt;that&lt;/em&gt; much more work ... but given the size of GDELT, I would have to start paying for using the BigQuery service that often.)&lt;/p&gt;
&lt;p&gt;As with any more substantive project, there was a lot of data cleaning and obstacles. Namely: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ISIS not recognized by GDELT&lt;/strong&gt;:
There's lots of International Militarized Groups (IMGs) recognized by GDELT, but ISIS seems to be too new in the headlines to be recognized by GDELT coding yet. Hence I had to look for substitutes:&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IMG (International Militarized Group) tag to the rescue&lt;/strong&gt;:
There is a column specifying actor &lt;em&gt;type&lt;/em&gt; (not actor name!) for each event. There is an actor type IMG, which was fortunate. However, there is no way of fully knowing whether said group is ISIS or not from this dataset. (At least with this level of granularity, but I am sure it would be technically possible, if GDELT team so chose.) I would also imagine that the fighters on the ground themselves are often not quite sure, given the number of splinter groups these organizations harbor.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;But sometimes "REB"&lt;/strong&gt;:
When individually inspecting the events (just some of them, I do not have the time to go through the entire data dump), I quickly realized that the data pertaining to clearly ISIS attacks are sometimes labeled as "REBEL" actor type. So I needed to include both in the analysis.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cleaning the data&lt;/strong&gt;:
For some events it is hard, if not impossible, to correctly specify precise coordinates. As a result, GDELT merely inputs the values of the approximate center of Syria. These records obviously needed to be removed from the dataset. Obviously, there was couple of more steps that I needed to do and a couple that tricked me for a little bit, for instance, when I found that the state code of one of the events was &lt;em&gt;IS&lt;/em&gt;, which, however, stood for Israel, as I later found out.  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The GDELT project classifies each event using &lt;a href="http://gdeltproject.org/data/lookups/CAMEO.eventcodes.txt"&gt;one of their internal codes&lt;/a&gt;, each of these codes then gets then a &lt;a href="http://web.pdx.edu/~kinsella/jgscale.html"&gt;Goldstein score&lt;/a&gt;, which basically expresses whether this event whether people are being nice to each other (positive score) or mean/evil towards each other (negative score). Where +10.0 is some massive humanitarian/developmental aid project, +1.0 is probably visit of some minor national politician. All the positive things were filtered out, because I wanted to focus on what the problems were. There -1.1 is, for instance, "Deny an attributed policy, action, role or position" and -10.0 is "Military attack; clash; assault".&lt;/p&gt;
&lt;p&gt;As the more SQL-knowledgeable of you might have noticed, I only considered events that came from 2 independent sources and happened on or after March 2013. &lt;/p&gt;
&lt;h1 id='explore'&gt; Let's explore &lt;/h1&gt;

&lt;p&gt;With this dataset in hand, I made several maps where I plotted each event as a point sized according to its Goldstein score and set relatively low transparency so that all hotspots appear in bright red. I plotted this dataset by month, and here's March 2013 till July 2013. We see that at the end of this period, there's was violence spearing from its initial hotspots. &lt;/p&gt;
&lt;h3&gt;March and April 2013&lt;/h3&gt;
&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201303.png" alt="Map of Syria" align="left" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201304.png" alt="Map of Syria" align="right" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;h3&gt;May and July 2013&lt;/h3&gt;
&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201305.png" alt="Map of Syria" align="left" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201307.png" alt="Map of Syria" align="right" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;Now, if we look at the period August till November, we see that there's a lot more violence then. But to some extent we have to bear in mind that this dataset includes &lt;em&gt;all&lt;/em&gt; rebels and not just ISIS. &lt;/p&gt;
&lt;h3&gt;August 2013&lt;/h3&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201308.png" alt="Map of Syria" align="center" style="width: 620px;"/&gt;&lt;/p&gt;
&lt;h3&gt;September 2013&lt;/h3&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201309.png" alt="Map of Syria" align="center" style="width: 620px;"/&gt;&lt;/p&gt;
&lt;h3&gt;October 2013&lt;/h3&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201310.png" alt="Map of Syria" align="center" style="width: 620px;"/&gt;&lt;/p&gt;
&lt;h3&gt;November 2013&lt;/h3&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201311.png" alt="Map of Syria" align="center" style="width: 620px;"/&gt;&lt;/p&gt;
&lt;p&gt;Moreover, we have to consider the connected events: &lt;/p&gt;
&lt;script type="text/javascript" src="//www.google.com/trends/embed.js?hl=en-US&amp;q=Syria,+Chemical+Weapons&amp;date=1/2013+12m&amp;cmpt=q&amp;content=1&amp;cid=TIMESERIES_GRAPH_0&amp;export=5&amp;w=500&amp;h=330"&gt;&lt;/script&gt;

&lt;p&gt;Here, I am using Google Trends as a proxy for "Western interest" in the matter. We can see that the use of chemical drew Western attention to Syria, however, this interest was very short-lived.&lt;/p&gt;
&lt;p&gt;Clearly, August and September are easily explained by the usage of chemical weapons. But the violence following this, especially in October and later, cannot be explained just by looking at chemical weapons, because that is when the hype ended and has not picked up until ISIS was the next important thing.&lt;/p&gt;
&lt;p&gt;The following months were similarly violent and few in the West seemed to care. &lt;/p&gt;
&lt;h3&gt;December 2013 and January 2014&lt;/h3&gt;
&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201312.png" alt="Map of Syria" align="left" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201401.png" alt="Map of Syria" align="right" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;h3&gt;February and March 2014&lt;/h3&gt;
&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201402.png" alt="Map of Syria" align="left" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201403.png" alt="Map of Syria" align="right" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;h3&gt;April and May 2014&lt;/h3&gt;
&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201404.png" alt="Map of Syria" align="left" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201405.png" alt="Map of Syria" align="right" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;If we plot the Google trend graph again, since the start of Syrian Civil War in March 2011, we see that the attention Syria got around the times of the use of chemical weapons is unparalleled. This is hardly surprising, but what is notable is that there a &lt;a href="http://www.cbsnews.com/news/syria-chemical-weapons-attack-blamed-on-assad-but-wheres-the-evidence/"&gt;disagreement regarding who actually used them&lt;/a&gt;, though I think that at least some of these attacks were sure to be made by the government. &lt;/p&gt;
&lt;script type="text/javascript" src="//www.google.com/trends/embed.js?hl=en-US&amp;cat=0-16-396&amp;q=Syria&amp;date=1/2009+43m&amp;cmpt=q&amp;content=1&amp;cid=TIMESERIES_GRAPH_1&amp;export=5&amp;w=500&amp;h=330"&gt;&lt;/script&gt;

&lt;p&gt;But despite the limited interested by the West, violence was actually similar to the months during which the chemical weapons were used. &lt;/p&gt;
&lt;p&gt;What is interesting that ISIS was not picked up by Western media much until recent months, despite the fact that ISIS can be traced back to 2004: &lt;/p&gt;
&lt;script type="text/javascript" src="//www.google.com/trends/embed.js?hl=en-US&amp;cat=0-16-396&amp;q=%22Islamic+State%22,+ISIS,+ISIL&amp;date=today+12-m&amp;cmpt=q&amp;content=1&amp;cid=TIMESERIES_GRAPH_0&amp;export=5&amp;w=500&amp;h=330"&gt;&lt;/script&gt;

&lt;p&gt;Still, violence was hovering around the same level:&lt;/p&gt;
&lt;h3&gt;June and July 2014&lt;/h3&gt;
&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201406.png" alt="Map of Syria" align="left" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201407.png" alt="Map of Syria" align="right" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;h3&gt;August and September 2014&lt;/h3&gt;
&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201408.png" alt="Map of Syria" align="left" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/201409.png" alt="Map of Syria" align="right" style="width: 310px;"/&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;It is interesting that it seems that despite the limited budget that ISIS has for its media operations, its terror tactics are largely successful: Syria is not, at least by according to this analysis, by and large, more violent than it was in the few months prior to ISIS' inclusion in the Western media's limelight. &lt;em&gt;Yet&lt;/em&gt;, ISIS get substantial amount of attention, so much so that it prodded United States and &lt;em&gt;five Arab&lt;/em&gt; states (no European states, however, at the time of writing) to launch a military operation starting today. This article used a lot of proxies so I do not want to make grandiose claims that cannot be supported by this analysis.&lt;/p&gt;
&lt;p&gt;Nevertheless, I think what this article shows that ISIS first and foremost is unparalleled by its usage of social media compared to other terrorist organiztations and splinter groups. If anything, it seems that the number of violent occurrences has decreased. But the terror-tactics and the headline-grabbing strategy of ISIS is already working well for them. West pays attention. &lt;/p&gt;
&lt;p&gt;At the same time, the brutality and the casualities is hard to really compare, because the information about the previous comparable systems (e.g. &lt;a href="http://en.wikipedia.org/wiki/Islamic_Emirate_of_Afghanistan"&gt;Islamic Emirate of Afghanistan&lt;/a&gt;) is very limited and we might just never get as complete picture as we have now. But now, largely thanks to GDELT, we have a much more complete dataset about the conditions within the Islamic State and so it might prove easier to benchmark the level of violence and discord in this society against all other -- be it present or future -- states. &lt;/p&gt;
&lt;p&gt;I am currently working on an interactive R-Shiny app for this visualization/analysis so stay tuned!&lt;/p&gt;
&lt;p&gt;Want the R script? Want to give feedback? Comments? Question? I am happy to hear it! Contact me at james [dot] langr [at] gmail [dot] com.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakub Langr</dc:creator><pubDate>Mon, 22 Sep 2014 21:00:00 +0100</pubDate><guid>tag:,2014-09-22:tracking-crisis.html</guid><category>modeling</category><category>GDELT</category><category>R</category><category>Syria</category></item><item><title>Predictions R hard</title><link>/hello-world.html</link><description>&lt;h1&gt;... or quick and dirty statistical modeling in R&lt;/h1&gt;
&lt;p&gt;Recently, I decided to start a blog and my ongoing involvement in the &lt;a href="http://goodjudgmentproject.com/"&gt;Good Judgment Project (GJP)&lt;/a&gt;, which is part of US government's &lt;a href="http://www.iarpa.gov"&gt;Intelligence Advanced Research Projects Activity (IARPA)&lt;/a&gt;, more specifically the ACE Project, proved to be a decent excuse to do so. &lt;/p&gt;
&lt;p&gt;I have joined GJP mid-Season 3 (hence I haven't participated fully) and then I tested into season 4 (combination of general intelligence test and political knowledge). This test alone was a treat, because it followed all the guidelines about best practices of hiring (to my knowledge) and I knew that if I get in, this will be a lot of fun. What I did not know at the time was that only one in ten will actually be accepted into GJP, otherwise I would probably put in a lot more work into the test.&lt;/p&gt;
&lt;p&gt;Despite this mess-up, I joined a project and met my amazing fellow forecasters in my team. At the time of joining, I already knew that I will be putting numeric probabilistic values on how the world might soon turn out to be (e.g. will there be a direct Russia-Ukraine confrontation in Crimea). All of these questions are well-defined using a very sophisticated set of definitions, but making the evaluation criteria very flexible and as to allow GJP Team to 'resolve' each question in the spirit rather than the letter of the question.&lt;/p&gt;
&lt;p&gt;Number of these questions have allowed for use of publicly available datasets and so I would like to offer some code that I used to ease up my work as a forecaster. This particular example is relates to a question that resolved yesterday: If on a certain date the area of ice on the Arctic sea will be more than what it was last year.&lt;/p&gt;
&lt;p&gt;The following R code downloads, cleans and plots some time-series representation of the record ed data of the ice for the past couple of years. It is &lt;em&gt;super-simple&lt;/em&gt;, but I was able to do it from question to quantitative probabilities in about 30 minutes, so this is just to demonstrate that even such simple code can help you make a much more solid prediction. This was necessary, because my team's forecasts were all over the place (among 9 forecasters we ranged 5-80%) and statistical modeling is a great way how to deal with data that is normally quite counter-intuitive and complex.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;TTR&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;reshape&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;tseries&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;library&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;forecast&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="c1"&gt;# Loading, cleaning (missing values are by default assigned value of -9999)&lt;/span&gt;
read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;http://www.ijis.iarc.uaf.edu/seaice/extent/plot_v2.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; data
&lt;span class="kp"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;,&lt;/span&gt;data&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;-9999&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kc"&gt;NA&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; data
&lt;span class="kp"&gt;colSums&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;is.na&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Melt changes the columns (there is a column for each year) into just one column &amp;#39;value&amp;#39;&lt;/span&gt;
data_ts &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; melt&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;18&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
ts &lt;span class="o"&gt;=&lt;/span&gt; ts&lt;span class="p"&gt;(&lt;/span&gt;data_ts&lt;span class="p"&gt;,&lt;/span&gt; deltat&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;365&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
data_ts &lt;span class="o"&gt;=&lt;/span&gt; na.remove&lt;span class="p"&gt;(&lt;/span&gt;ts&lt;span class="p"&gt;[,&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;# Decomposes the time-series plots the decomposition and the forecast (as well as prints it)&lt;/span&gt;
decomposed_ts &lt;span class="o"&gt;=&lt;/span&gt; decompose&lt;span class="p"&gt;(&lt;/span&gt;data_ts&lt;span class="p"&gt;)&lt;/span&gt;
plot&lt;span class="p"&gt;(&lt;/span&gt;decomposed_ts&lt;span class="p"&gt;)&lt;/span&gt;
ts_forecast &lt;span class="o"&gt;=&lt;/span&gt; HoltWinters&lt;span class="p"&gt;(&lt;/span&gt;data_ts&lt;span class="p"&gt;,&lt;/span&gt;gamma&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;F&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
forecasts &lt;span class="o"&gt;=&lt;/span&gt; forecast.HoltWinters&lt;span class="p"&gt;(&lt;/span&gt;ts_forecast&lt;span class="p"&gt;,&lt;/span&gt;h&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
forecasts
plot.forecast&lt;span class="p"&gt;(&lt;/span&gt;forecasts&lt;span class="p"&gt;)&lt;/span&gt;
data&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;250&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;260&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="kt"&gt;c&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;18&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;For GJP purposes, the confidence intervals produced by this model are especially useful, because they give you an idea of how confident you can be in your predictions:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; forecasts 
Point Forecast Lo &lt;span class="m"&gt;80&lt;/span&gt; Hi &lt;span class="m"&gt;80&lt;/span&gt; Lo &lt;span class="m"&gt;95&lt;/span&gt; Hi &lt;span class="m"&gt;95&lt;/span&gt; 
&lt;span class="m"&gt;16.73710&lt;/span&gt; &lt;span class="m"&gt;4981786&lt;/span&gt; &lt;span class="m"&gt;4920648&lt;/span&gt; &lt;span class="m"&gt;5042924&lt;/span&gt; &lt;span class="m"&gt;4888284&lt;/span&gt; &lt;span class="m"&gt;5075288&lt;/span&gt; 
&lt;span class="m"&gt;16.73995&lt;/span&gt; &lt;span class="m"&gt;4963324&lt;/span&gt; &lt;span class="m"&gt;4867154&lt;/span&gt; &lt;span class="m"&gt;5059494&lt;/span&gt; &lt;span class="m"&gt;4816245&lt;/span&gt; &lt;span class="m"&gt;5110403&lt;/span&gt; 
&lt;span class="m"&gt;16.74279&lt;/span&gt; &lt;span class="m"&gt;4944862&lt;/span&gt; &lt;span class="m"&gt;4814956&lt;/span&gt; &lt;span class="m"&gt;5074768&lt;/span&gt; &lt;span class="m"&gt;4746188&lt;/span&gt; &lt;span class="m"&gt;5143536&lt;/span&gt; 
&lt;span class="m"&gt;16.74564&lt;/span&gt; &lt;span class="m"&gt;4926399&lt;/span&gt; &lt;span class="m"&gt;4762199&lt;/span&gt; &lt;span class="m"&gt;5090600&lt;/span&gt; &lt;span class="m"&gt;4675277&lt;/span&gt; &lt;span class="m"&gt;5177522&lt;/span&gt; 
&lt;span class="m"&gt;16.74849&lt;/span&gt; &lt;span class="m"&gt;4907937&lt;/span&gt; &lt;span class="m"&gt;4708313&lt;/span&gt; &lt;span class="m"&gt;5107562&lt;/span&gt; &lt;span class="m"&gt;4602638&lt;/span&gt; &lt;span class="m"&gt;5213237&lt;/span&gt; 
&lt;span class="m"&gt;16.75134&lt;/span&gt; &lt;span class="m"&gt;4889475&lt;/span&gt; &lt;span class="m"&gt;4653078&lt;/span&gt; &lt;span class="m"&gt;5125872&lt;/span&gt; &lt;span class="m"&gt;4527937&lt;/span&gt; &lt;span class="m"&gt;5251014&lt;/span&gt; 
&lt;span class="m"&gt;16.75419&lt;/span&gt; &lt;span class="m"&gt;4871013&lt;/span&gt; &lt;span class="m"&gt;4596412&lt;/span&gt; &lt;span class="m"&gt;5145614&lt;/span&gt; &lt;span class="m"&gt;4451047&lt;/span&gt; &lt;span class="m"&gt;5290979&lt;/span&gt; 
&lt;span class="m"&gt;16.75704&lt;/span&gt; &lt;span class="m"&gt;4852551&lt;/span&gt; &lt;span class="m"&gt;4538291&lt;/span&gt; &lt;span class="m"&gt;5166811&lt;/span&gt; &lt;span class="m"&gt;4371932&lt;/span&gt; &lt;span class="m"&gt;5333170&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One of the plots here can help elucidate why my team might have been all over the place: there are many factors influencing how much ice there will be on a given day: sure, there is the seasonal (summer-winter) cycle, which matters a lot, but there is also some random element as well as measurement error. I fear that lots of my fellow forecasters (perhaps including myself for a long time) fell victim to &lt;a href="http://en.wikipedia.org/wiki/Overfitting"&gt;over-fitting&lt;/a&gt; to the random element. Sure, we could observe the pattern from the previous year, but no one from the team--to my knowledge--plotted the data to see what (approximate) influence each of the two factors have. This is why decomposition is so great:&lt;/p&gt;
&lt;h2&gt;Decomposed time-series plot&lt;/h2&gt;
&lt;p&gt;&lt;img src="https://dl.dropboxusercontent.com/u/30848031/blog/gjp_modelling_ts_decomposition.svg" alt="Timeseries decomposition of ice-area" align="center" style="width: 620px;"/&gt;&lt;/p&gt;
&lt;p&gt;One interesting element of the decomposition is the trend, which I was expecting to see fairly clear evidence of global warming, but instead I really found out "just" evidence of climate change. Though, of course, I am no climatologist, so perhaps that interesting dip in the year 2000 had some other (spurious?) reasons. &lt;/p&gt;
&lt;p&gt;The decomposition, although helpful, was not what I considered the main advantage of this little exercise: I was then able to use a time-series statistical model called HoltWinters to predict the area of ice (no pun intended?), which uses exponential smoothing that is quite fitting in these conditions (I wonder whether these statistical puns significantly affect my readership?). This model is appropriate mainly because there is a lot of historical data and the data is always very constrained to a certain range (e.g. a 3 sigma change is &lt;em&gt;actually&lt;/em&gt; extremely unlikely, which cannot be said of all financial data this model is applied to). &lt;/p&gt;
&lt;h1&gt;Thoughts about GJP itself&lt;/h1&gt;
&lt;p&gt;GJP is what I think social science should be: quantifiable, based on best-practices and aiming to get as close to the truth as possible, not tell the best story. This was, interestingly enough, the conclusion (&lt;em&gt;simplifying tremendously&lt;/em&gt;) of Professor Philip Teltock in &lt;a href="http://www.amazon.com/Expert-Political-Judgment-Good-Know/dp/0691128715"&gt;his book Expert Political Judgment&lt;/a&gt;. Namely that the political forecasters that tell the best story are usually favored by the media, because it sells well, but they tend to do worse than most others on accuracy. Professor Tetlock is now one of the main organizers of GJP and so it is a great honor to work as his lab rat, because it helps to do cutting-edge research and it helps me to learn a ton in the process.&lt;/p&gt;
&lt;p&gt;One additional gift every forecaster got from the GJP was a set of presentations of best practices of forecasting, which I think were fascinating, albeit oftentimes simple guidelines to stick to. But as with everything, it is much more a matter of putting these into practice rather that makes a great forecaster. &lt;/p&gt;
&lt;p&gt;Couple of interesting things that I noticed about myself looking at old predictions: &lt;/p&gt;
&lt;h2&gt;1. I am overly cautious&lt;/h2&gt;
&lt;p&gt;Reading loads of literature about randomness and its role in human society (Kahneman, Taleb, Tversky, Ariely, Mlodinow etc.) I was overly careful about putting down anything close to 1% or 99%, even though some questions call for it (likelihood of a massive reform of international institutions in a short timespan). Good Judgment, after all, is not only very well calibrated, but it is also very discriminating. &lt;/p&gt;
&lt;h2&gt;2. I struggle with randomness&lt;/h2&gt;
&lt;p&gt;Interesting point about randomness--to some extent related to the previous one--how do we square the fact that randomness is just a model and yet we keep on invoking the properties of randomness when talking about the world. But, at least on the level of humans, each action is supposedly deterministic. Yes, some might call on the &lt;a href="http://www.quantumdiaries.org/2014/07/04/wrong/"&gt;famous George Box quote&lt;/a&gt;, but that does not really answer why in a situation of imperfect information &lt;em&gt;random&lt;/em&gt; is the &lt;em&gt;best&lt;/em&gt; model. This is especially confusing given the amount of strategic interaction and social influence in the world. &lt;/p&gt;
&lt;p&gt;This turned out to be a problem with with some of the GJP predictions I make, because I want to stick to randomness as a baseline (because it seems to be best practice), but then struggle to always justify this to myself and square it with the rest of information. This especially bothered me outside of GJP, however. In Mlodinow's book &lt;a href="http://www.amazon.com/The-Drunkards-Walk-Randomness-Rules/dp/0307275175"&gt;The Drunkard's Walk&lt;/a&gt;, he specifically used the example of production studio's CEOs as someone who is faced with great randomness in the movies. But each action in this immensely complex chain of interactions is deterministic, strategic and influenced by one's surroundings. Why is randomness an emergent property of human systems? Seems non-obvious.&lt;/p&gt;
&lt;h2&gt;3. Conditional interaction is hard&lt;/h2&gt;
&lt;h3&gt;(especially cross-culture)&lt;/h3&gt;
&lt;p&gt;There was a question on what would DPRK do, should the United States take a bold, but merely supportive, military action in aid of South Korea. Our team struggled to agree even if the bold action would increase chance of state DPRK being more aggressive towards South Korea or less so. Would the desire to prove something to US (or more generally, the West) outweigh the potential risks, because of the importance of the precedent or would the bold action scare off DPRK? Both ways of reasoning sounded equally plausible to me at the time so I just followed what my initial prediction was. But really, there was no reason for it. The question whether I got it right or wrong is irrelevant in this case; the question is: would I be able to make a good prediction next time? I fear that so far the answer is no and so I never swayed too far off 50%. I will probably need to devise a way of breaking these ties.&lt;/p&gt;
&lt;p&gt;Feedback? Comments? Question? I am happy to hear it! Contact me at james [dot] langr [at] gmail [dot] com.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakub Langr</dc:creator><pubDate>Sun, 14 Sep 2014 21:00:00 +0100</pubDate><guid>tag:,2014-09-14:hello-world.html</guid><category>modeling</category><category>R</category><category>statistics</category><category>GJP</category></item><item><title>About Me</title><link>/about.html</link><description>&lt;p&gt;&lt;img alt="Me" src="https://dl.dropboxusercontent.com/u/30848031/blog/WebSummit_011.JPG" title="Welcome to my blog!" /&gt;&lt;/p&gt;
&lt;p&gt;Welcome to my blog! I am a final year undergraduate at University of Oxford studying mostly economics, but really just spending loads of time on &lt;a href="http://coursera.org"&gt;Coursera.org&lt;/a&gt; and similar awesome MOOC sites (I mean, I have to love them, I already finished 12 courses...) playing with machine learning, data science, statistics, computer science and all the things awesome.&lt;/p&gt;
&lt;p&gt;I love to hack data and I worked in a data science position for a half a year at Pearson Plc, but I also have full-time like experience from international consultancies and NGOs. &lt;/p&gt;
&lt;p&gt;If you want to, feel free to get in touch at james [dot] langr [at] gmail [dot] com or via the LinkedIn profile in links! &lt;/p&gt;
&lt;p&gt;My resume available &lt;a href="http://goo.gl/sEUFMa"&gt;here&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Jakub Langr</dc:creator><pubDate>Sun, 14 Sep 2014 20:00:00 +0100</pubDate><guid>tag:,2014-09-14:about.html</guid><category>me</category><category>CV</category></item></channel></rss>
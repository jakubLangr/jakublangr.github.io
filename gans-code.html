<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.dropotron.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/skel-layers.min.js"></script>
    <script src="/js/init.js"></script>
    <link rel="stylesheet" href="/css/pygment.css" />
    <noscript>
        <link rel="stylesheet" href="/css/skel.css" />
        <link rel="stylesheet" href="/css/style.css" />
        <link rel="stylesheet" href="/css/style-noscript.css" />
    </noscript>
    <script src="//cdnjs.cloudflare.com/ajax/libs/modernizr/2.6.2/modernizr.min.js"></script>
    <link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
    <link  href="http://fonts.googleapis.com/css?family=Anonymous+Pro:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css" >
    <!--[if lte IE 8]><link rel="stylesheet" href="/css/ie/v8.css" /><![endif]-->
    <!--[if lte IE 9]><link rel="stylesheet" href="/css/ie/v9.css" /><![endif]-->
        <link href="http://www.jakublangr.com/feed/index.html" type="application/atom+xml" rel="alternate" title="Jakub Langr's Blog-Feed" />

    <title>Coding for GANS & (Semi)-Learning | Jakub Langr's Blog  Business, AI & Shower Thoughts</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width">
</head>

<body class=" loading">



    <!-- Header -->
    <header id="header" >
        <h1 class="logo">
            <a href=".">Jakub Langr's Blog </span></a>
        </h1>
        <nav id="nav">
            <ul>
                <!-- <li class="current"><a href="index.html">Welcome</a></li> -->
                <li class="submenu">
                    <a href="./">Blog</a>
                    <ul>
                            <li >
                                <a href="./category/about.html">About</a>
                            </li>
                            <li >
                                <a href="./category/non-technical.html">non-technical</a>
                            </li>
                            <li class="active">
                                <a href="./category/technical.html">technical</a>
                            </li>
                    </ul>
                </li>
                <li><a href="#" class="button special">Sign Up</a></li>
            </ul>
        </nav>
    </header>

<!-- Main -->
<article id="main">

  <header class="special container">
    <span class="icon fa-"></span>
    <h2>Coding for GANS & (Semi)-Learning</h2>
    <!-- add page sub title here -->
    <p>Posted on 10/09/2017 by Jakub Langr</p>
    <p></p>
  </header>

  <!-- One -->
    <section class="wrapper style4 container">

      <!-- Content -->
        <div class="content">
          <section>
            <!-- <a href="#" class="image feature"><img src="images/pic04.jpg" alt="" /></a> -->
            <h3>Posted in <a href="./category/technical.html">technical</a></h3>
            <p class="tags">
                <a href="./tag/python.html">python</a>
                <a href="./tag/ai.html">AI</a>
                <a href="./tag/semi-supervised-learning.html">semi-supervised learning</a>
                <a href="./tag/gans.html">GANs</a>
                <a href="./tag/generative.html">Generative</a>
                <a href="./tag/adverserial.html">Adverserial</a>
                <a href="./tag/neural-networks.html">Neural Networks</a>
                <a href="./tag/code.html">code</a>
</p>
            <p><h2>Intro</h2>
<p>I'll jump straight into what we have explained on a high-level <a href="http://jakublangr.com/gans-tutorial.html">last time</a>. The code is also available on <a href="https://github.com/jakubLangr/Gans-Semi-Supervised/blob/master/gans_semi_supervised_learning.ipynb">GitHub</a> and on <a href="https://medium.com/@james.langr">Medium</a>. This part is identical to the Jupyter notebook, except it is lacking the code output.</p>
<h2>Generative Adverserial Networks &amp; Semi-Supervised Learning</h2>
<h1>By Jakub Langr (originally written March 2017)</h1>
<p>This code was written for me to experiment with some of the recent advancements in AI. I chose specificially semi-supervised learning and Generative Adverserial Networks (GANs) to push myself. Some of the code was done as a homework for the <a href="https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow-iv">Creative Applications of Deep Learning Course</a>, which was extremely helpful in helping me learn about modern AI. Some of the broad framework came as pre-coded set-up and explanations for the last part of the course by <a href="https://www.linkedin.com/in/pkmital">Parag Mital</a>, but this usage of his code is completely novel and took a lot of engineering, stitching together and abstractions.
In this Jupyter Notebook I do the following things:
1. Import all the necessary dependencies (as well as some that I just used during development but not in final version)
2. Use a GAN approach to generate synethic images. 
    + More specifically, <a href="http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/">this recently extremely popular unsupervised technique</a> can learn the higher representations of what constitutes a human face (along with many attributes in the latent space) on the <a href="mmlab.ie.cuhk.edu.hk/projects/CelebA.html">Celeb Dataset</a> by competing another network to fool each other (explained later)
    + Alternatively, one can think of this approach as using an auto-encoder-style gene generative model that tries to generate new examples based on a seeding factor.
3. This seeding factor or 'latent feature space' invariably encode some aspects of the generative models and once understood, can be used to predictiably manipulate the nature of generated images--e.g. baldness, gender or smile. 
4. We can therefore generate an almost infinite supply of new examples and because we know how we manipulate the latent space, we can know their labels. In this example, we created 40,000 of Men and Women faces that can now be used for further training
5. Then we train the next layer classifier on the synthetic data for a binary classification of men or women faces.  Instead of training a new classifier from scratch, however, we use a <code>transfer learning</code> approach using Oxford's <code>Visual Geometry Group</code> or <code>vgg16</code> pre-trained network to get higher accuracy without having to training for days on a massive cluster.
6. We use the different <code>vgg16</code> Celebrity face predictions (<code>2623</code> to be exact) and train a simple fully connected two-layer neural network on the synthetic examples with the labels. (This is in stead of the typical transfer learning approach that cuts off the last layer and trains on those. Here we simply split that into 2 steps)
7. Use the 100 hand-labelled (by me) examples to evalute the accuracy of the new classifier.</p>
<h3>Motivation</h3>
<p>This is really exciting because it allow us to train classifier with having virtually no labelled data as long as we have lots of unlabelled data, <a href="http://jakublangr.com/ai-2016-review.html">which is a tremendously promising strategy especially for smaller companies with smaller datasets</a>.</p>
<h3>Brief definition of terms:</h3>
<p><strong>Semi-supervised learning</strong>: is basically using unlabelled data in addition labelled data during the traing process</p>
<p><strong>Generative Adverserial Netwokrs</strong>: explained in detail below</p>
<p>The code was done in <code>Tensorflow 1.0.0</code>.</p>
<div class="highlight"><pre><span></span><span class="c1"># First check the Python version</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span> <span class="o">&lt;</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;You are running an older version of Python!</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">,</span>
          <span class="s1">&#39;You should consider updating to Python 3.4.0 or&#39;</span><span class="p">,</span>
          <span class="s1">&#39;higher as the libraries built for this course&#39;</span><span class="p">,</span>
          <span class="s1">&#39;have only been tested in Python 3.4 and higher.</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Try installing the Python 3.5 version of anaconda&#39;</span>
          <span class="s1">&#39;and then restart `jupyter notebook`:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span>
          <span class="s1">&#39;https://www.continuum.io/downloads</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Now get necessary libraries</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
    <span class="kn">import</span> <span class="nn">pickle</span>
    <span class="kn">import</span> <span class="nn">tflearn</span>
    <span class="kn">import</span> <span class="nn">pickle</span>
    <span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
    <span class="kn">import</span> <span class="nn">random</span>
    <span class="kn">import</span> <span class="nn">multiprocessing</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
    <span class="kn">from</span> <span class="nn">skimage.transform</span> <span class="kn">import</span> <span class="kp">resize</span>
    <span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">data</span>
    <span class="kn">from</span> <span class="nn">scipy.misc</span> <span class="kn">import</span> <span class="n">imresize</span>
    <span class="kn">from</span> <span class="nn">scipy.ndimage.filters</span> <span class="kn">import</span> <span class="n">gaussian_filter</span>
    <span class="kn">import</span> <span class="nn">IPython.display</span> <span class="kn">as</span> <span class="nn">ipyd</span>
    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
    <span class="kn">from</span> <span class="nn">libs</span> <span class="kn">import</span> <span class="n">utils</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">dataset_utils</span><span class="p">,</span> <span class="n">nb_utils</span>
<span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Make sure you have started notebook in the same directory&quot;</span><span class="p">,</span>
          <span class="s2">&quot;as the provided zip file which includes the &#39;libs&#39; folder&quot;</span><span class="p">,</span>
          <span class="s2">&quot;and the file &#39;utils.py&#39; inside of it.  You will NOT be able&quot;</span><span class="p">,</span>
          <span class="s2">&quot;to complete this assignment unless you restart jupyter&quot;</span><span class="p">,</span>
          <span class="s2">&quot;notebook inside the directory created by extracting&quot;</span><span class="p">,</span>
          <span class="s2">&quot;the zip file or cloning the github repo.&quot;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

<span class="c1"># We&#39;ll tell matplotlib to inline any drawn figures like so:</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
</pre></div>


<p><a name="part-1---generative-adversarial-networks-gan--deep-convolutional-gan-dcgan"></a></p>
<h1>Generative Adversarial Networks (GAN) / Deep Convolutional GAN (DCGAN)</h1>
<p><a name="introduction"></a></p>
<h2>Introduction</h2>
<p>Recall that a Generative Adversarial Network is two networks, a generator and a discriminator.  The "generator" takes a feature vector and decodes this feature vector to become an image. The discriminator is exactly like the encoder of the Autoencoder, except it can only have 1 value in the final layer.  We use a sigmoid to squash this value between 0 and 1, and then interpret the meaning of it as: 1, the image you gave me was real, or 0, the image you gave me was generated by the generator, it's a FAKE! So the discriminator is like an encoder which takes an image and then perfoms lie detection.  Are you feeding me lies?  Or is the image real?  </p>
<p>Consider the AutoEncoders for instance.  The loss function operated partly on the input space.  It said, per pixel, what is the difference between my reconstruction and the input image?  The l2-loss per pixel.  Recall at that time we suggested that this wasn't the best idea because per-pixel differences aren't representative of our own perception of the image.  One way to consider this is if we had the same image, and translated it by a few pixels.  We would not be able to tell the difference, but the per-pixel difference between the two images could be enormously high.</p>
<p>The GAN does not use per-pixel difference.  Instead, it trains a distance function: the discriminator.  The discriminator takes in two images, the real image and the generated one, and learns what a similar image should look like!  That is really the amazing part of this network and has opened up some very exciting potential future directions for unsupervised learning.  Another network that also learns a distance function is known as the siamese network.  We didn't get into this network in this course, but it is commonly used in facial verification, or asserting whether two faces are the same or not.</p>
<p>The GAN network is notoriously a huge pain to train!  For that reason, we won't actually be training it.  Instead, we'll discuss an extension to this basic network called the VAEGAN (Variational Auto Encoder GAN). For now, let's stick with creating the GAN.</p>
<p>Let's first create the two networks: the discriminator and the generator.  We'll first begin by building a general purpose encoder which we'll use for our discriminator.  What we want is for the input placeholder to be encoded using a list of dimensions for each of our encoder's layers.  In the case of a convolutional network, our list of dimensions should correspond to the number of output filters.  We also need to specify the kernel heights and widths for each layer's convolutional network.</p>
<p>We'll first need a placeholder.  This will be the "real" image input to the discriminator and the discrimintator will encode this image into a single value, 0 or 1, saying, yes this is real, or no, this is not real.</p>
<p>This description was kindly provided by Parag under <a href="http://jakublangr.com/ai-2016-review.html">MIT License</a>.</p>
<div class="highlight"><pre><span></span>net = CV.get_celeb_vaegan_model()
</pre></div>


<p>We'll load the graph_def contained inside this dictionary.  It follows the same idea as the <code>inception</code>, <code>vgg16</code>, and <code>i2v</code> pretrained networks.  It is a dictionary with the key <code>graph_def</code> defined, with the graph's pretrained network.  It also includes <code>labels</code> and a <code>preprocess</code> key.  We'll have to do one additional thing which is to turn off the random sampling from variational layer.  This isn't really necessary but will ensure we get the same results each time we use the network.  We'll use the <code>input_map</code> argument to do this.  Don't worry if this doesn't make any sense, as we didn't cover the variational layer in any depth.  Just know that this is removing a random process from the network so that it is completely deterministic.  If we hadn't done this, we'd get slightly different results each time we used the network (which may even be desirable for your purposes).</p>
<p>Now let's get the relevant parts of the network: <code>X</code>, the input image to the network, <code>Z</code>, the input image's encoding, and <code>G</code>, the decoded image.  In many ways, this is just like the Autoencoders we learned about above, except instead of <code>Y</code> being the output, we have <code>G</code> from our generator!  And the way we train it is very different: we use an adversarial process between the generator and discriminator, and use the discriminator's own distance measure to help train the network, rather than pixel-to-pixel differences.</p>
<div class="highlight"><pre><span></span>X = g.get_tensor_by_name(&#39;net/x:0&#39;)
Z = g.get_tensor_by_name(&#39;net/encoder/variational/z:0&#39;)
G = g.get_tensor_by_name(&#39;net/generator/x_tilde:0&#39;)
</pre></div>


<p>Let's get some data to play with:</p>
<div class="highlight"><pre><span></span>files = sorted(datasets.CELEB())
img_i = 20
img = plt.imread(files[img_i])
plt.imshow(img)
</pre></div>


<p>Exploring the Celeb Net Attributes¶
Let's now try and explore the attributes of our dataset. We didn't train the network with any supervised labels, but the Celeb Net dataset has 40 attributes for each of its 200k images. These are already parsed and stored for you in the net dictionary:</p>
<p>Find the Latent Encoding for an Attribute
The Celeb Dataset includes attributes for each of its 200k+ images. This allows us to feed into the encoder some images that we know have a specific attribute, e.g. "smiling". We store what their encoding is and retain this distribution of encoded values. We can then look at any other image and see how it is encoded, and slightly change the encoding by adding the encoded of our smiling images to it! The result should be our image but with more smiling. That is just insane and we're going to see how to do it. First lets inspect our latent space:
Latent Feature Arithmetic
Let's now try to write a general function for performing everything we've just done so that we can do this with many different features. We'll then try to combine them and synthesize people with the features we want them to have...</p>
<div class="highlight"><pre><span></span>def get_features_for(label=&#39;Bald&#39;, has_label=True, n_imgs=50):
    # Helper function to obtain labels and then preprocessing and returning
    # a vector for the seeding function for GAN
    # basically figures out the embedding for a particular attribute
    label_i = net[&#39;labels&#39;].index(label)
    label_idxs = np.where(net[&#39;attributes&#39;][:, label_i] == has_label)[0]
    label_idxs = np.random.permutation(label_idxs)[:n_imgs]
    imgs = [plt.imread(files[img_i])[..., :3]
            for img_i in label_idxs]
    preprocessed = np.array([CV.preprocess(img_i) for img_i in imgs])
    zs = sess.run(Z, feed_dict={X: preprocessed})
    return np.mean(zs, 0)
</pre></div>


<p>Now we use the code to create an interpolation between "Male" and "Not Male" (Female) images. Because we are only using the two endpoints, we get two images: a 100% Man and 100% Woman (please note that we can also get anything in between by doing a weighed average of the two seeding vectors).</p>
<div class="highlight"><pre><span></span>def gan_generate_data(num_iter=20000,imgs=15):
    # generates 2*(number of iter) images 
    # adding random number of pictures for each synthesis (to increase variation)
    # returns list of [Male, Female] * num_iter images
    generated_images = []

    for i in range(num_iter):

        n_imgs = random.choice(range(imgs-10, imgs+10))

        z1 = get_features_for(&#39;Male&#39;, True, n_imgs=n_imgs)
        z2 = get_features_for(&#39;Male&#39;, False, n_imgs=n_imgs)

        notmale_vector = z2 - z1
        amt = np.linspace(0, 1, 2)
        zs = np.array([z1 + notmale_vector*amt_i for amt_i in amt])
        g = sess.run(G, feed_dict={Z: zs})

        generated_images.append(g[0])
        generated_images.append(g[1])

        if i%1000==0:
            print(&#39;Iteration number : {}&#39;.format(i))

    return generated_images

generated_data = gan_generate_data()
</pre></div>


<p>Okay good, we have the data to play around with and it's saved in a pickle file so we don't have to re-create it. Now, let's just add one hot encoded labels (we have done this in predictable manner -- i.e. male (0) is always first). We can just sense-check it and get the shape of the overall sample.</p>
<div class="highlight"><pre><span></span>labels = [0,1] * 20000
generated_data = np.array(generated_data)
generated_data.shape
</pre></div>


<p><a name="extensions"></a></p>
<h2>Extensions</h2>
<p>Now let's get to the transfer learning part. First we have to get out network, <code>vgg16</code>.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">libs</span> <span class="kn">import</span> <span class="n">vgg16</span><span class="p">,</span> <span class="n">inception</span><span class="p">,</span> <span class="n">i2v</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">vgg16</span><span class="o">.</span><span class="n">get_vgg_face_model</span><span class="p">()</span>
</pre></div>


<h2>Transfer Learning</h2>
<p>Here we get the <code>vgg16</code> network, which we have loaded up earlier and use it to generate the predictions for one of its own pre-trained classes. However, since we want to predict a different task, we then use the <code>transferred_predictions</code> function to get the predictions for the 2623 different classes and then use that as an input to the next classifier to train it on recognizing gender. </p>
<p>In order to do this effectively we must first do some image processing, which we do in <code>transferred_df</code>.</p>
<div class="highlight"><pre><span></span><span class="s s-Atom">def</span> <span class="nf">transferred_predictions</span><span class="p">(</span><span class="s s-Atom">img</span><span class="p">)</span><span class="s s-Atom">:</span>
    <span class="s s-Atom">#</span> <span class="s s-Atom">gets</span> <span class="s s-Atom">an</span> <span class="nf">image</span> <span class="p">(</span><span class="err">`</span><span class="s s-Atom">np</span><span class="p">.</span><span class="s s-Atom">array</span><span class="err">`</span><span class="p">)</span> <span class="s s-Atom">as</span> <span class="s s-Atom">an</span> <span class="s s-Atom">input</span> <span class="s s-Atom">outputs</span> <span class="s s-Atom">net&#39;s final layer predictions </span>
<span class="s s-Atom">    results = []</span>

<span class="s s-Atom">    # Grab the tensor defining the input to the network</span>
<span class="s s-Atom">    x = g.get_tensor_by_name(names[0] + &quot;:0&quot;)</span>

<span class="s s-Atom">    # And grab the tensor defining the softmax layer of the network</span>
<span class="s s-Atom">    softmax = g.get_tensor_by_name(names[-2] + &quot;:0&quot;)</span>

<span class="s s-Atom">    with tf.Session(graph=g) as sess, g.device(&#39;</span><span class="o">/</span><span class="nn">cpu</span><span class="p">:</span><span class="sc">0&#39;)</span><span class="s s-Atom">:</span>
        <span class="s s-Atom">#</span> <span class="nv">Remember</span> <span class="s s-Atom">from</span> <span class="s s-Atom">the</span> <span class="s s-Atom">lecture</span> <span class="s s-Atom">that</span> <span class="s s-Atom">we</span> <span class="s s-Atom">have</span> <span class="s s-Atom">to</span> <span class="s s-Atom">set</span> <span class="s s-Atom">the</span> <span class="s s-Atom">dropout</span>
        <span class="s s-Atom">#</span> <span class="s2">&quot;keep probability&quot;</span> <span class="s s-Atom">to</span> <span class="mf">1.0</span><span class="p">.</span>
        <span class="s s-Atom">res</span> <span class="o">=</span> <span class="s s-Atom">softmax</span><span class="p">.</span><span class="nf">eval</span><span class="p">(</span><span class="s s-Atom">feed_dict=</span><span class="p">{</span><span class="nn">x</span><span class="p">:</span> <span class="s s-Atom">img</span> <span class="p">}</span> <span class="p">)</span> <span class="s s-Atom">#</span> <span class="p">,</span> <span class="nv">Not</span> <span class="s s-Atom">using</span> <span class="s s-Atom">droput</span> <span class="s s-Atom">here</span>
                    <span class="s s-Atom">#</span> <span class="s s-Atom">&#39;net/dropout_1/random_uniform:0&#39;:</span> <span class="p">[[</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4096</span><span class="p">],</span>
                    <span class="s s-Atom">#</span> <span class="s s-Atom">&#39;net/dropout/random_uniform:0&#39;:</span> <span class="p">[[</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4096</span><span class="p">]})</span>
        <span class="s s-Atom">test_array</span> <span class="o">=</span> <span class="s s-Atom">res</span><span class="p">.</span><span class="nf">argsort</span><span class="p">()[</span><span class="o">-</span><span class="mi">5</span><span class="s s-Atom">:</span><span class="p">][</span><span class="s s-Atom">::-</span><span class="mi">1</span><span class="p">].</span><span class="nf">flatten</span><span class="p">()</span>
        <span class="s s-Atom">results</span> <span class="o">=</span> <span class="p">([(</span><span class="s s-Atom">res</span><span class="p">.</span><span class="nf">flatten</span><span class="p">()[</span><span class="nf">int</span><span class="p">(</span><span class="s s-Atom">idx</span><span class="p">)],</span> 
                <span class="s s-Atom">net</span><span class="p">[</span><span class="s s-Atom">&#39;labels&#39;</span><span class="p">][</span><span class="nf">int</span><span class="p">(</span><span class="s s-Atom">idx</span><span class="p">)])</span>
               <span class="s s-Atom">for</span> <span class="s s-Atom">idx</span> <span class="s s-Atom">in</span> <span class="s s-Atom">test_array</span> <span class="p">])</span>

        <span class="s s-Atom">result</span> <span class="o">=</span> <span class="s s-Atom">pd</span><span class="p">.</span><span class="nv">DataFrame</span><span class="p">(</span><span class="s s-Atom">results</span><span class="p">,</span> <span class="s s-Atom">columns</span><span class="o">=</span><span class="p">[</span><span class="s s-Atom">&#39;score&#39;</span><span class="p">,</span><span class="s s-Atom">&#39;label&#39;</span><span class="p">])</span> <span class="s s-Atom">#</span> <span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="s s-Atom">columns=&#39;score&#39;</span><span class="p">)</span>

        <span class="s s-Atom">results</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="s s-Atom">result</span><span class="p">.</span><span class="s s-Atom">score</span><span class="p">)</span>

    <span class="s s-Atom">return</span> <span class="s s-Atom">results</span>

<span class="s s-Atom">def</span> <span class="nf">transferred_df</span><span class="p">(</span><span class="s s-Atom">generated_data</span><span class="p">)</span><span class="s s-Atom">:</span>
    <span class="s s-Atom">#</span> <span class="s s-Atom">does</span> <span class="s s-Atom">the</span> <span class="s s-Atom">preprocessing</span> <span class="s s-Atom">of</span> <span class="s s-Atom">the</span> <span class="err">`</span><span class="s s-Atom">list</span><span class="err">`</span> <span class="s s-Atom">of</span> <span class="s s-Atom">generated_data</span> <span class="s s-Atom">and</span> <span class="s s-Atom">outputs</span> <span class="err">`</span><span class="s s-Atom">list</span><span class="err">`</span> <span class="s s-Atom">of</span> <span class="s s-Atom">predictions</span>
    <span class="s s-Atom">results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="s s-Atom">for</span> <span class="s s-Atom">i</span> <span class="s s-Atom">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="s s-Atom">generated_data</span><span class="p">))</span><span class="s s-Atom">:</span>
        <span class="s s-Atom">img</span> <span class="o">=</span> <span class="nf">imresize</span><span class="p">(</span><span class="s s-Atom">generated_data</span><span class="p">[</span><span class="s s-Atom">i</span><span class="p">],</span> <span class="s s-Atom">size=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
        <span class="s s-Atom">img</span> <span class="o">=</span> <span class="s s-Atom">net</span><span class="p">[</span><span class="s s-Atom">&#39;preprocess&#39;</span><span class="p">](</span><span class="s s-Atom">img</span><span class="p">)[</span><span class="s s-Atom">np</span><span class="p">.</span><span class="s s-Atom">newaxis</span><span class="p">]</span>
        <span class="s s-Atom">result</span> <span class="o">=</span> <span class="nf">transferred_predictions</span><span class="p">(</span><span class="s s-Atom">img</span><span class="p">)</span>
        <span class="s s-Atom">results</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="s s-Atom">result</span><span class="p">)</span>

        <span class="s s-Atom">if</span> <span class="s s-Atom">i</span><span class="c1">%1000==0:</span>
            <span class="nf">print</span><span class="p">(</span><span class="s2">&quot;Current image id {}&quot;</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="s s-Atom">i</span><span class="p">))</span>

    <span class="s s-Atom">return</span> <span class="s s-Atom">results</span>


<span class="s s-Atom">def</span> <span class="nf">parallel_transfer_eval</span><span class="p">(</span><span class="s s-Atom">generated_data</span><span class="p">)</span><span class="s s-Atom">:</span>
    <span class="s s-Atom">#</span> <span class="s s-Atom">returns</span> <span class="s s-Atom">parallely</span> <span class="s s-Atom">executed</span> <span class="err">`</span><span class="s s-Atom">transferred_df</span><span class="err">`</span> <span class="s s-Atom">using</span> <span class="s s-Atom">first</span> <span class="nf">split</span> <span class="p">(</span><span class="s s-Atom">fs</span><span class="p">),</span> <span class="nf">second</span> <span class="p">(</span><span class="s s-Atom">ss</span><span class="p">)</span> <span class="s s-Atom">and</span> <span class="nf">third</span> <span class="p">(</span><span class="s s-Atom">ts</span><span class="p">)</span> <span class="s s-Atom">as</span> <span class="s s-Atom">divisors</span>
    <span class="s s-Atom">pool</span> <span class="o">=</span> <span class="s s-Atom">multiprocessing</span><span class="p">.</span><span class="nv">Pool</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
    <span class="s s-Atom">fs</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="s s-Atom">generated_data</span><span class="p">)</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span>
    <span class="s s-Atom">ss</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="nf">len</span><span class="p">(</span><span class="s s-Atom">generated_data</span><span class="p">)</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span>
    <span class="s s-Atom">ts</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="nf">len</span><span class="p">(</span><span class="s s-Atom">generated_data</span><span class="p">)</span><span class="o">/</span><span class="mi">4</span><span class="p">)</span>
    <span class="s s-Atom">target</span> <span class="o">=</span> <span class="s s-Atom">generated_data</span><span class="p">[</span><span class="s s-Atom">:fs</span><span class="p">],</span> <span class="s s-Atom">generated_data</span><span class="p">[</span><span class="nn">fs</span><span class="p">:</span><span class="s s-Atom">ss</span><span class="p">],</span> <span class="s s-Atom">generated_data</span><span class="p">[</span><span class="nn">ss</span><span class="p">:</span><span class="s s-Atom">ts</span><span class="p">],</span><span class="s s-Atom">generated_data</span><span class="p">[</span><span class="nn">ts</span><span class="p">:]</span>
    <span class="s s-Atom">results</span> <span class="o">=</span> <span class="s s-Atom">pool</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="s s-Atom">transferred_df</span><span class="p">,</span> <span class="nf">zip</span><span class="p">(</span><span class="s s-Atom">target</span><span class="p">))</span>
    <span class="s s-Atom">#</span> <span class="s s-Atom">results</span> <span class="o">=</span> <span class="nv">Parallel</span><span class="p">(</span><span class="s s-Atom">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)(</span><span class="nf">delayed</span><span class="p">(</span><span class="s s-Atom">transferred_df</span><span class="p">)(</span><span class="s s-Atom">img</span><span class="p">)</span> <span class="s s-Atom">for</span> <span class="s s-Atom">img</span> <span class="s s-Atom">in</span> <span class="s s-Atom">generated_data</span><span class="p">)</span>

    <span class="s s-Atom">return</span> <span class="s s-Atom">results</span>
</pre></div>


<h2>Leveraging transfer learning</h2>
<p>Now we use the predictions made by <code>vgg16</code> in a typical <a href="http://cs231n.github.io/transfer-learning/">Transfer Learning</a> paradigm. Here we just take the last layer of predictions, reshape the features and feed it to a next layer classifier (sometimes also done by removing the last (few) Fully Connected Layers) and putting training the whole network. Here we just create a new one just on the last layer. The practice supports both approaches. </p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># train-test for proper evaluation</span>
<span class="n">train_X</span><span class="p">,</span> <span class="n">test_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="p">)</span>

<span class="n">tflearn</span><span class="o">.</span><span class="n">init_graph</span><span class="p">(</span><span class="n">num_cores</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">gpu_memory_fraction</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># set up the network</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">input_data</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">2623</span><span class="p">])</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">regression</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">)</span>

<span class="c1"># train</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tflearn</span><span class="o">.</span><span class="n">DNN</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">generated_data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">validation_set</span><span class="o">=</span><span class="n">train_X</span><span class="p">)</span>


<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># reshape labels so that they match what the network expects</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Male&#39;</span><span class="p">,</span> <span class="s1">&#39;Female&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10000</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">labels</span><span class="o">.</span><span class="n">shape</span>

<span class="n">test_imgs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">CV</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="nb">file</span><span class="p">))</span> <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">files</span><span class="p">[:</span><span class="mi">100</span><span class="p">]])</span>
<span class="n">test_imgs</span><span class="o">.</span><span class="n">shape</span>
</pre></div>


<p>And we're done with this bit as we have scores for both generated and hand-labelled images (test)! This only is the first step, however, in our journey, as now we have to transfer the <code>vgg16</code> generated scores onto the new classifier (the last bit in transfer learning, which is typically simplified by cutting off the last layer and just re-running the network with a new final layer, but here done explicitly for training purposes.)</p>
<h2>Training and evaluating a new classifier</h2>
<p>For simplicity, we will just use the <code>tflearn</code> classifier so that we have an easier job using transfer learning given the complexity of all the previous work:
1. we train (based on the synthetic data and the therefore completely predictable labels)
2. we evalute on the handlablled examples (by me) </p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>


<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10000</span>

<span class="n">feature_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">real_valued_column</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">2623</span><span class="p">)]</span>


<span class="n">classifier</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">learn</span><span class="o">.</span><span class="n">DNNClassifier</span><span class="p">(</span><span class="n">feature_columns</span><span class="o">=</span><span class="n">feature_columns</span><span class="p">,</span>
                                            <span class="n">hidden_units</span><span class="o">=</span><span class="p">[</span><span class="mi">2623</span><span class="p">,</span><span class="mi">512</span><span class="p">],</span>
                                            <span class="n">gradient_clip_norm</span><span class="o">=.</span><span class="mo">01</span><span class="p">,</span>
                                            <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
                                            <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                                            <span class="c1"># model_dir=&#39;./model&#39;)</span>

<span class="c1"># Fit model.</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">array</span><span class="p">,</span>
               <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
               <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
               <span class="n">steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>


<span class="c1"># Evaluate accuracy.</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
       <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
       <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
       <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># test_array = np.array([ [res[0] for res in result] for result in test_array ])</span>

<span class="n">accuracy_score</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">test_array</span><span class="p">,</span>
                                     <span class="n">y</span><span class="o">=</span><span class="n">test_labels</span><span class="p">)[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: {0:f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">))</span>
</pre></div>


<h1>General discussion</h1>
<p>The results were not that stellar, however, I think this is a fascinating research area and quite likely it is going to be one of the biggest areas for the future of AI: but we still got better than random (consistently) and might get better if I spent more time on this.</p>
<p>Moreover this code can probably fine-tuned and re-used with only minor modifications in many industry applications:
(a) 3D object generation
(b) <a href="https://www.youtube.com/watch?v=u7kQ5lNfUfg">Pix2Pix applications</a> that manages to create new images based on style or just a generation of maps from satelite images. The possibilities here are <em>literally endless</em>.
(c) Remastering Old Movies.
Just to name a few.</p>
<p>Thank you for reading and if any of this was of interest, explore this website for more!</p></p>
          </section>
        </div>

    </section>

    <!-- Two -->
    <section class="wrapper style1 container special">
        <div class="row">
          <div class="4u">

            <section>
              <span class="icon feature fa-"></span>
              <header>
                <a href="./iclr19-gans.html" rel='bookmark'><h3>GANs & applied ML @ ICLR 2019</h3></a>
              </header>
              <p>I have just returned from ICLR 2019 in New Orleans and what a fruitful year that was on GAN papers-we saw papers on image synthesis (BigGAN), audio (WaveGAN), feature selection (KnockoffGAN), 3</p>
              <footer>
                  <ul class="buttons">
                      <li><a href="./iclr19-gans.html" class="button small">Read More</a></li>
                  </ul>
              </footer>
            </section>

          </div>
          <div class="4u">

            <section>
              <span class="icon feature fa-"></span>
              <header>
                <a href="./gan-innovations.html" rel='bookmark'><h3>AI Gets Creative Thanks To GANs Innovations</h3></a>
              </header>
              <p>For an Artificial Intelligence (AI) professional, or data scientist, the barrage of AI-marketing can evoke very different feelings than for a general audience. For one thing, the AI indu</p>
              <footer>
                  <ul class="buttons">
                      <li><a href="./gan-innovations.html" class="button small">Read More</a></li>
                  </ul>
              </footer>
            </section>

          </div>
          <div class="4u">

            <section>
              <span class="icon feature fa-"></span>
              <header>
                <a href="./icml-gans.html" rel='bookmark'><h3>List of ICML GAN Papers</h3></a>
              </header>
              <p>In all seriousness, however, I do respect greatly all the amazing work that the researchers at ICML have presented. I would not be capable of anywhere near their level of work so kudos to them</p>
              <footer>
                  <ul class="buttons">
                      <li><a href="./icml-gans.html" class="button small">Read More</a></li>
                  </ul>
              </footer>
            </section>

          </div>
        </div>
    </section>
  </article>

  <div id="comments">
      <h2 class="space-above">Comments</h2>
      <div id="disqus_thread"></div>
      <script type="text/javascript">
          var disqus_identifier = "gans-code.html";
          (function() {
              var dsq = document.createElement('script');
              dsq.type = 'text/javascript';
              dsq.async = true;
              dsq.src = 'http://jakublangr.disqus.com/embed.js';
              (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
          })();
      </script>
      <noscript>Please enable JavaScript to view <a href="http://disqus.com/?ref_noscript">comments</a>.</noscript>
  </div>


<!-- Footer -->
<footer id="footer">

    <ul class="icons">
        <li>
          <a href="http://linkedin.com/in/jakublangr" class="icon circle fa fa-LinkedIn"><span class="label">LinkedIn</span></a>
        </li>
        <li>
          <a href="https://github.com/jakubLangr" class="icon circle fa fa-GitHub"><span class="label">GitHub</span></a>
        </li>
        <li>
          <a href="http://twitter.com/LangrJakub" class="icon circle fa fa-Twitter"><span class="label">Twitter</span></a>
        </li>
        <li>
          <a href="mailto:james.langr@gmail.com" class="icon circle fa fa-envelope"><span class="label">envelope</span></a>
        </li>
        <li>
          <a href="/about.html" class="icon circle fa fa-Info"><span class="label">Info</span></a>
        </li>
        <li>
          <a href="http://r-bloggers.com" class="icon circle fa fa-blog"><span class="label">blog</span></a>
        </li>
    </ul>

    <span class="copyright">&copy; Untitled. All rights reserved. Design: <a href="http://html5up.net">HTML5 UP</a>.</span>

    <!-- Google Analytics -->
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-55040887-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<!-- End Google Analytics -->

</footer>
</body>
</html>